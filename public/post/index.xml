<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on DNA confesses Data speak</title>
    <link>/post/</link>
    <description>Recent content in Posts on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 -0500</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>clustering scATACseq data: the TF-IDF way</title>
      <link>/post/clustering-scatacseq-data-the-tf-idf-way/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/clustering-scatacseq-data-the-tf-idf-way/</guid>
      <description>scATACseq data are very sparse. It is sparser than scRNAseq. To do clustering of scATACseq data, there are some preprocessing steps need to be done.
I want to reproduce what has been done after reading the method section of these two recent scATACseq paper:
A Single-Cell Atlas of In Vivo Mammalian Chromatin Accessibility Darren et.al Cell 2018   Latent Semantic Indexing Cluster Analysis  In order to get an initial sense of the relationship between individual cells, we first broke the genome into 5kb windows and then scored each cell for any insertions in these windows, generating a large, sparse, binary matrix of 5kb windows by cells for each tissue.</description>
    </item>
    
    <item>
      <title>plot 10x scATAC coverage by cluster/group</title>
      <link>/post/plot-10x-scatac-coverage-by-cluster-group/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/plot-10x-scatac-coverage-by-cluster-group/</guid>
      <description>This post was inspired by Andrew Hill’s recent blog post.
Inspired by some nice posts by @timoast and @tangming2005 and work from @10xGenomics. Would still definitely have to split BAM files for other tasks, so easy to use tools for that are super useful too!
&amp;mdash; Andrew J Hill (@ahill_tweets) April 13, 2019  Andrew wrote that blog post in light of my other recent blog post and Tim’s (developer of the almighty Seurat package) blog post.</description>
    </item>
    
    <item>
      <title>Use docopt to write command line R utilities </title>
      <link>/post/use-docopt-to-write-command-line-r-utilities/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/use-docopt-to-write-command-line-r-utilities/</guid>
      <description>I was writing an R script to plot the ATACseq fragment length distribution and wanted to turn the R script to a command line utility.
I then (re)discovered this awesome docopt.R. One just needs to write the help message the you want to display and docopt() will parse the options, arguments and return a named list which can be accessed inside the R script. check http://docopt.org/ for more information as well.</description>
    </item>
    
    <item>
      <title>Split a 10xscATAC bam file by cluster</title>
      <link>/post/split-a-10xscatac-bam-file-by-cluster/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/split-a-10xscatac-bam-file-by-cluster/</guid>
      <description>I want to split the PBMC scATAC bam from 10x by cluster id. So, I can then make a bigwig for each cluster to visualize in IGV.
The first thing I did was googling to see if anyone has written such a tool (Do not reinvent the wheels!). People have done that because I saw figures from the scATAC papers. I just could not find it. Maybe I need to refine my googling skills.</description>
    </item>
    
    <item>
      <title>understand 10x scRNAseq and scATAC fastqs</title>
      <link>/post/understand-10x-scrnaseq-and-scatac-fastqs/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/understand-10x-scrnaseq-and-scatac-fastqs/</guid>
      <description>single cell RNAseq Please read the following posts by Dave Tang. When I google, I always find his posts on top of the pages. Thanks for sharing your knowledge.
https://davetang.org/muse/2018/06/06/10x-single-cell-bam-files/ https://davetang.org/muse/2018/08/09/getting-started-with-cell-ranger/
From the 10x manual:
 The final Single Cell 3’ Libraries contain the P5 and P7 primers used in Illumina bridge amplification PCR. The 10x Barcode and Read 1 (primer site for sequencing read 1) is added to the molecules during the GEMRT incubation.</description>
    </item>
    
    <item>
      <title>How to make a transcript to gene mapping file</title>
      <link>/post/how-to-make-a-transcript-to-gene-mapping-file/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-make-a-transcript-to-gene-mapping-file/</guid>
      <description>I need a transcript to gene mapping file for Salmon. I am aware of annotation bioconductor packages that can do this job. However, I was working on a species which does not have the annotation in a package format (I am going to use Drosphila as an example for this blog post). I had to go and got the gtf file and made such a file from scratch.
Please read the specifications of those two file formats.</description>
    </item>
    
    <item>
      <title>Understanding p value, multiple comparisons, FDR and q value</title>
      <link>/post/understanding-p-value-multiple-comparisons-fdr-and-q-value/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/understanding-p-value-multiple-comparisons-fdr-and-q-value/</guid>
      <description>UPDATE 01/29/2019. Read this awesome paper Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations.
This was an old post I wrote 3 years ago after I took HarvardX: PH525.3x Advanced Statistics for the Life Sciences on edx taught by Rafael Irizarry. It is still one of the best courses to get you started using R for genomics. I am very thankful to have those high quality classes available to me when I started to learn.</description>
    </item>
    
    <item>
      <title>permutation test for PCA components</title>
      <link>/post/permute-test-for-pca-components/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/permute-test-for-pca-components/</guid>
      <description>PCA is a critical method for dimension reduction for high-dimensional data. High-dimensional data are data with features (p) a lot more than observations (n). However, this is changing with single-cell RNAseq data. Now, we can sequence millions (n) of single cells and each cell has ~20,000 genes/features (p).
I suggest you read my previous blog post on using svd to calculate PCs.
Single-cell expression data PCA In single-cell RNAseq analysis, feature selection will be performed first.</description>
    </item>
    
    <item>
      <title>The end of 2018</title>
      <link>/post/the-end-of-2018/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-end-of-2018/</guid>
      <description>It is almost the end of 2018. It is a good time to review what I have achieved during the year and look forward to a brand new 2019. I wrote a similar post for 2017 here.
Some highlights of the year 2018:  My son Noah Tang was born in April. He is so lovely and we love him so much. Can&amp;rsquo;t believe he is almost 9 months old.</description>
    </item>
    
    <item>
      <title>A tale of two heatmap functions</title>
      <link>/post/a-tale-of-two-heatmap-functions/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-tale-of-two-heatmap-functions/</guid>
      <description>You probably do not understand heatmap! Please read You probably don’t understand heatmaps by Mick Watson
In the blog post, Mick used heatmap function in the stats package, I will try to walk you through comparing heatmap, and heatmap.2 from gplots package.
Before I start, I want to quote this:
 “The defaults of almost every heat map function in R does the hierarchical clustering first, then scales the rows then displays the image”</description>
    </item>
    
    <item>
      <title>PCA in action</title>
      <link>/post/pca-in-action/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pca-in-action/</guid>
      <description>PCA in practice. Principle Component Analysis(PCA) is a very important skill for dimention reduction to analyze high-dimentional data. High-dimentional data are data with features (p) a lot more than observations (n). This types of data are very commonly generated from high-throuput sequencing experiments. For example, an RNA-seq or microarry experiment measures expression of tens of thousands of genes for only 8 samples (4 controls and 4 treatments).
Let’s use a microarray data for demonstration.</description>
    </item>
    
    <item>
      <title>Merge featureCount table from RNAseq</title>
      <link>/post/merge-featurecount-table-from-rnaseq/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/merge-featurecount-table-from-rnaseq/</guid>
      <description>featureCounts is a program to fast summarize counts from sequencing data. I use it to get gene-level RNAseq counts by
featureCounts -p -t exon -g gene_id -a annotation.gtf -o mysample_featureCount.txt mapping_results_PE.bam
If you have a lot of samples, you will get a lot of *featureCount.txt and you will need to merge them for downstream analysis.
I will show you how to merge the tables using R, python and unix below.</description>
    </item>
    
    <item>
      <title>Three gotchas when using R for Genomic data analysis</title>
      <link>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</guid>
      <description>During my daily work with R for genomic data analysis, I encountered several instances that R gives me some (bad) surprises.
1. The devil 1 and 0 coordinate system read detail here https://github.com/crazyhottommy/DNA-seq-analysis#tips-and-lessons-learned-during-my-dna-seq-data-analysis-journey
some files such as bed file is 0 based. Two genomic regions:
chr1 0 1000 chr1 1001 2000  when you import that bed file into R using rtracklayer::import(), it will become
chr1 1 1000 chr1 1002 2000  The function convert it to 1 based internally (R is 1 based unlike python).</description>
    </item>
    
    <item>
      <title>open files on remote with sublime by ssh</title>
      <link>/post/open-files-on-remote-with-sublime-by-ssh/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/open-files-on-remote-with-sublime-by-ssh/</guid>
      <description>I am still suck at vim or emacs. I use nano to edit files on remote machines. But for more complicated editing, I prefer to use sublime.
use this https://github.com/randy3k/RemoteSubl for editing remote files.
Steps:
on remote machine, install rmate ssh bio1 curl -o ~/bin/rmate https://raw.githubusercontent.com/aurora/rmate/master/rmate chmod u+x bin/rmate  on your local computer, install RemoteSubl on your local computer, open sublime, click tools &amp;ndash;&amp;gt; Command Palette &amp;ndash;&amp;gt; type Package control:Install Package &amp;ndash;&amp;gt; type RemoteSubl to install.</description>
    </item>
    
    <item>
      <title>set up odyssey HPC dot files</title>
      <link>/post/set-up-odyssey-hpc-dot-files/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-odyssey-hpc-dot-files/</guid>
      <description>dot files Those files are originally got from Samir Amin, my labmate in Roel Verhaak&amp;rsquo;s lab. Thanks for sharing!
.screenrc
.bashrc
.bash_profile
and inside .profile.d folder, there is a file named 01_odyssey_config.sh. It was executed when you login the shell.
You can grab my dot files in my github repo.
Inside the .bash_profile:
if [ -d $HOME/.profile.d ]; then for i in $HOME/.profile.d/*.sh; do if [ -r $i ]; then if [ &amp;quot;${-#*i}&amp;quot; !</description>
    </item>
    
    <item>
      <title>set up ssh odyssey HPC</title>
      <link>/post/set-up-ssh-odyssey-hpc/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-ssh-odyssey-hpc/</guid>
      <description>request an account following here.
 Harvard odyssey HPC requires a two-factor security login. First set up the VPN following here
 Then read about OpenAuth here. One can download mobile apps such as Duo and google-Authenticator on your phone, but then each time you will need to type the password to the terminal. Or you can download the java program for desktop, if you have a FAS research computing account, you should be able to download it from the link FASRC send you.</description>
    </item>
    
    <item>
      <title>set up my new mac laptop</title>
      <link>/post/set-up-my-new-mac-laptop/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-my-new-mac-laptop/</guid>
      <description>I am starting my first day at Harvard FAS informatics and I will keep a note here on how I set up my new laptop.
customize terminal following this gist:
download iterm2 for mac here.
install on-my-zsh sh -c &amp;quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;quot;  You will have to install git first for the upper command to work. Now, when you fire up your terminal, it looks much more prettier! (there are many other schemes for oh my zsh, I found the default is good.</description>
    </item>
    
    <item>
      <title>Compute averages/sums on GRanges or equal length bins</title>
      <link>/post/compute-averages-sums-on-granges-or-equal-length-bins/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/compute-averages-sums-on-granges-or-equal-length-bins/</guid>
      <description>Googling is a required technique for programmers. Once I have a programming problem in mind, the first thing I do is to google to see if other people have encountered the same problem and maybe they already have a solution. Do not re-invent the wheels. Actually, reading other people’s code and mimicing their code is a great way of learning. Today, I am going to show you how to compute binned averages/sums along a genome or any genomic regions of interest.</description>
    </item>
    
    <item>
      <title>my first try on Rmarkdown using blogdown</title>
      <link>/post/my-first-try-on-rmarkdown-using-blogdown/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/my-first-try-on-rmarkdown-using-blogdown/</guid>
      <description>I have used blogdown writing regular markdown posts, but the real power is from the Rmarkdown! let me try it for this post.
Note that you do not knit the Rmarkdown by yourself, rather you let blogdown do the heavy lift.
library(tidyverse)  ## Loading tidyverse: ggplot2 ## Loading tidyverse: tibble ## Loading tidyverse: tidyr ## Loading tidyverse: readr ## Loading tidyverse: purrr ## Loading tidyverse: dplyr  ## Warning: package &#39;tibble&#39; was built under R version 3.</description>
    </item>
    
    <item>
      <title>hugo academic theme blog down deployment (some details)</title>
      <link>/post/hugo-academic-theme-blog-down-deployment-some-details/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hugo-academic-theme-blog-down-deployment-some-details/</guid>
      <description>I have been following this tutorial from Alison and tips from Leslie Myint for some customization for deploying my blogdown website
It is quite straightforward to have a working site following Alison&amp;rsquo;s guide. However, you always want some customization of your own site.
I took the tips from Leslie.
changed the menue bar to black. I like it better than the default white. in the config.toml file, change the theme:</description>
    </item>
    
    <item>
      <title>Backup automatically with cron</title>
      <link>/post/crontab-for-backup/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/crontab-for-backup/</guid>
      <description>Data backup is an essential step in the data analysis life cycle. As shown in a pic below taken from DataOne.
There are so many important things you may want to back up: your raw/processed data, your code, and your dot configuration files. While for every project, I have git version control my scripts (not the data) and push it to github or gitlab to have a backup, big files can not be hosted on github or gitlab.</description>
    </item>
    
    <item>
      <title>How to upload files to GEO</title>
      <link>/post/how-to-upload-files-to-geo/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-upload-files-to-geo/</guid>
      <description>readings links: http://yeolab.github.io/onboarding/geo.html
http://www.hildeschjerven.net/Protocols/Submission_of_HighSeq_data_to_GEO.pdf
https://www.ncbi.nlm.nih.gov/geo/info/submissionftp.html
1. create account Go to NCBI GEO: http://www.ncbi.nlm.nih.gov/geo/ Create User ID and password. my username is research_guru
I used my google account.
2. fill in the xls sheet Downloaded the meta xls sheet from https://www.ncbi.nlm.nih.gov/geo/info/seq.html
## bgzip the fastqs cd 01seq find *fastq | parallel bgzip md5sum *fastq.gz &amp;gt; fastq_md5.txt # copy to excle cat fastq_md5.txt | awk &#39;{print $2}&#39; #copy to excle cat fastq_md5.</description>
    </item>
    
  </channel>
</rss>