<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses Data speak on DNA confesses Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses Data speak on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>cellranger mk reference with transgenes</title>
      <link>/post/cellranger-mk-reference-with-transgenes/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/cellranger-mk-reference-with-transgenes/</guid>
      <description>

&lt;h3 id=&#34;the-problem&#34;&gt;The problem&lt;/h3&gt;

&lt;p&gt;I am working on some 10x scRNAseq data from transgenic mouse. The cells express &lt;a href=&#34;https://www.fpbase.org/protein/tdtomato/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;Tdtomato&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Cre-Lox_recombination&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;Cre&lt;/code&gt;&lt;/a&gt; genes. I need to add those to the &lt;code&gt;cellranger&lt;/code&gt; reference to get the counts for those two genes.&lt;/p&gt;

&lt;h3 id=&#34;the-journey-to-the-solution&#34;&gt;The journey to the solution&lt;/h3&gt;

&lt;p&gt;Following &lt;a href=&#34;https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/references#addgene&#34; target=&#34;_blank&#34;&gt;https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/references#addgene&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I created a &lt;code&gt;fasta&lt;/code&gt; file for the two transgenes: &lt;code&gt;tdTomato&lt;/code&gt; and &lt;code&gt;Cre&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tdtomato_cre.fa&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;tdtomato dna:chromosome chromosome:GRCm38:tdtomato:1:1431:1 REF
ATGGTGAGCAAGGGCGAGGAGGTCATCAAAGAGTTCATGCGCTTCAAGGTGCGCATGGAGGGCTCCATGAACGGCCACGAGTTCGAGATCGAGGGCGAGGGCGAGGGCCGCCCCTACGAGGGCACCCAGACCGCCAAGCTGAAGGTGACCAAGGGCGGCCCCCTGCCCTTCGCCTGGGACATCCTGTCCCCCCAGTTCATGTACGGCTCCAAGGCGTACGTGAAGCACCCCGCCGACATCCCCGATTACAAGAAGCTGTCCTTCCCCGAGGGCTTCAAGTGGGAGCGCGTGATGAACTTCGAGGACGGCGGTCTGGTGACCGTGACCCAGGACTCCTCCCTGCAGGACGGCACGCTGATCTACAAGGTGAAGATGCGCGGCACCAACTTCCCCCCCGACGGCCCCGTAATGCAGAAGAAGACCATGGGCTGGGAGGCCTCCACCGAGCGCCTGTACCCCCGCGACGGCGTGCTGAAGGGCGAGATCCACCAGGCCCTGAAGCTGAAGGACGGCGGCCACTACCTGGTGGAGTTCAAGACCATCTACATGGCCAAGAAGCCCGTGCAACTGCCCGGCTACTACTACGTGGACACCAAGCTGGACATCACCTCCCACAACGAGGACTACACCATCGTGGAACAGTACGAGCGCTCCGAGGGCCGCCACCACCTGTTCCTGGGGCATGGCACCGGCAGCACCGGCAGCGGCAGCTCCGGCACCGCCTCCTCCGAGGACAACAACATGGCCGTCATCAAAGAGTTCATGCGCTTCAAGGTGCGCATGGAGGGCTCCATGAACGGCCACGAGTTCGAGATCGAGGGCGAGGGCGAGGGCCGCCCCTACGAGGGCACCCAGACCGCCAAGCTGAAGGTGACCAAGGGCGGCCCCCTGCCCTTCGCCTGGGACATCCTGTCCCCCCAGTTCATGTACGGCTCCAAGGCGTACGTGAAGCACCCCGCCGACATCCCCGATTACAAGAAGCTGTCCTTCCCCGAGGGCTTCAAGTGGGAGCGCGTGATGAACTTCGAGGACGGCGGTCTGGTGACCGTGACCCAGGACTCCTCCCTGCAGGACGGCACGCTGATCTACAAGGTGAAGATGCGCGGCACCAACTTCCCCCCCGACGGCCCCGTAATGCAGAAGAAGACCATGGGCTGGGAGGCCTCCACCGAGCGCCTGTACCCCCGCGACGGCGTGCTGAAGGGCGAGATCCACCAGGCCCTGAAGCTGAAGGACGGCGGCCACTACCTGGTGGAGTTCAAGACCATCTACATGGCCAAGAAGCCCGTGCAACTGCCCGGCTACTACTACGTGGACACCAAGCTGGACATCACCTCCCACAACGAGGACTACACCATCGTGGAACAGTACGAGCGCTCCGAGGGCCGCCACCACCTGTTCCTGTACGGCATGGACGAGCTGTACAAGTAA
&amp;gt;cre dna:chromosome chromosome:GRCm38:cre:1:1032:1 REF
ATGGCCAATTTACTGACCGTACACCAAAATTTGCCTGCATTACCGGTCGATGCAACGAGTGATGAGGTTCGCAAGAACCTGATGGACATGTTCAGGGATCGCCAGGCGTTTTCTGAGCATACCTGGAAAATGCTTCTGTCCGTTTGCCGGTCGTGGGCGGCATGGTGCAAGTTGAATAACCGGAAATGGTTTCCCGCAGAACCTGAAGATGTTCGCGATTATCTTCTATATCTTCAGGCGCGCGGTCTGGCAGTAAAAACTATCCAGCAACATTTGGGCCAGCTAAACATGCTTCATCGTCGGTCCGGGCTGCCACGACCAAGTGACAGCAATGCTGTTTCACTGGTTATGCGGCGGATCCGAAAAGAAAACGTTGATGCCGGTGAACGTGCAAAACAGGCTCTAGCGTTCGAACGCACTGATTTCGACCAGGTTCGTTCACTCATGGAAAATAGCGATCGCTGCCAGGATATACGTAATCTGGCATTTCTGGGGATTGCTTATAACACCCTGTTACGTATAGCCGAAATTGCCAGGATCAGGGTTAAAGATATCTCACGTACTGACGGTGGGAGAATGTTAATCCATATTGGCAGAACGAAAACGCTGGTTAGCACCGCAGGTGTAGAGAAGGCACTTAGCCTGGGGGTAACTAAACTGGTCGAGCGATGGATTTCCGTCTCTGGTGTAGCTGATGATCCGAATAACTACCTGTTTTGCCGGGTCAGAAAAAATGGTGTTGCCGCGCCATCTGCCACCAGCCAGCTATCAACTCGCGCCCTGGAAGGGATTTTTGAAGCAACTCATCGATTGATTTACGGCGCTAAGGATGACTCTGGTCAGAGATACCTGGCCTGGTCTGGACACAGTGCCCGTGTCGGAGCCGCGCGAGATATGGCCCGCGCTGGAGTTTCAATACCGGAGATCATGCAAGCTGGTGGCTGGACCAATGTAAATATTGTCATGAACTATATCCGTAACCTGGATAGTGAAACAGGGGCAATGGTGCGCCTGCTGGAAGATGGCGATTAG
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;edit-the-genome-fa-file&#34;&gt;edit the genome.fa file&lt;/h4&gt;

&lt;p&gt;The original mouse &lt;code&gt;genome.fa&lt;/code&gt; file is wrapped with 60 based per line, need to convert the transgene fasta to the same format.&lt;/p&gt;

&lt;p&gt;use &lt;a href=&#34;https://github.com/lh3/seqtk&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;seqtk&lt;/code&gt;&lt;/a&gt; from Heng Li.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;seqtk seq -l 60 tdtomato_cre.fa  &amp;gt; tdtomato_cre_multi.fa

mkdir ../../mm10-2.1.0_premrna_tdtomato_cre

cat genome.fa tdtomato_cre_multi.fa &amp;gt; ../../mm10-2.1.0_premrna_tdtomato_cre/genome.fa
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;edit-the-gtf-file&#34;&gt;edit the gtf file&lt;/h4&gt;

&lt;p&gt;create a tdtomato_cre.gtf:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tdtomato        custom  exon    1       1431    .       +       .       gene_id &amp;quot;ENSMUSGtdtomato&amp;quot;; gene_version &amp;quot;1&amp;quot;; transcript_id &amp;quot;tdtomato1&amp;quot;; gene_name &amp;quot;Tdtomato&amp;quot;
cre     custom  exon    1       1032    .       +       .       gene_id &amp;quot;ENSMUSGcre&amp;quot;; gene_version &amp;quot;1&amp;quot;; transcript_id &amp;quot;cre1&amp;quot;; gene_name &amp;quot;Cre&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be careful with the tabs and spaces. The &lt;code&gt;attributes&lt;/code&gt; column is at column 9 and separate the entries with space.
concatenate the original &lt;code&gt;genes.gtf&lt;/code&gt; with the transgene gtf:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat genes.gtf tdtomato_cre.gtf &amp;gt; ../../mm10-2.1.0_premrna_tdtomato_cre/genes.gtf
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;cellranger-mk-reference&#34;&gt;cellranger  mk reference&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cellranger mkref --genome=mm10-2.1.0_premrna_tdtomato_cre --fasta genome.fa --genes genes.gtf --nthreads 12 --memgb 30
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;the-problem-1&#34;&gt;The problem&lt;/h3&gt;

&lt;p&gt;After &lt;code&gt;cellranger-count&lt;/code&gt; and I used &lt;code&gt;Seurat&lt;/code&gt; to visualize the expression levels of &lt;code&gt;Cre&lt;/code&gt; and &lt;code&gt;Tdtomato&lt;/code&gt;. I see no cells express Tdtomato and very few cells express &lt;code&gt;Cre&lt;/code&gt;, which is very strange given that all cells are &lt;code&gt;red&lt;/code&gt; under microscope and we sorted out the cells using &lt;code&gt;Tdtomato&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I googled and found some other people have the same problem.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://bioinformatics.stackexchange.com/questions/6694/scrna-seq-10x-cellranger-pipelines-low-custom-tdtomato-gene-content-looking-for&#34; target=&#34;_blank&#34;&gt;https://bioinformatics.stackexchange.com/questions/6694/scrna-seq-10x-cellranger-pipelines-low-custom-tdtomato-gene-content-looking-for&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://bioinformatics.stackexchange.com/questions/4596/no-counts-for-added-gene-in-cellranger-scrna-seq&#34; target=&#34;_blank&#34;&gt;https://bioinformatics.stackexchange.com/questions/4596/no-counts-for-added-gene-in-cellranger-scrna-seq&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I then went to the &lt;code&gt;bam&lt;/code&gt; file:&lt;/p&gt;

&lt;p&gt;only 34 reads mapped to &lt;code&gt;Tdtomato&lt;/code&gt; gene&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;samtools view possorted_genome_bam.bam tdtomato | wc -l
34
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are more for &lt;code&gt;Cre&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;samtools view possorted_genome_bam.bam cre  | wc -l
6166

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is in agreement of the &lt;code&gt;FeaturePlot&lt;/code&gt; results.&lt;/p&gt;

&lt;p&gt;From the two links above, I realized 10x scRNAseq we are using is a 3&amp;rsquo; technology, only the 3 prime sequences are captured and sequenced. For the &lt;code&gt;Cre&lt;/code&gt; and &lt;code&gt;Tdtomato&lt;/code&gt; genes, I will need to add the 3&amp;rsquo;UTR sequences as well. Otherwise a lot of the reads will not be mapped.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is particular true for poorly annotated genome if you are working with non-model organisms. If the &lt;code&gt;gtf&lt;/code&gt; annotation of the 3&amp;rsquo;UTR is not complete or too short, you will get very low mapping rate for the genes.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;let-s-fix-the-problem&#34;&gt;Let&amp;rsquo;s fix the problem&lt;/h3&gt;

&lt;p&gt;The problem is that no one knows what is the 3&amp;rsquo; UTR of the transgenes. I have to somehow derive it from the reads.
I asked on twitter and &lt;a href=&#34;https://twitter.com/RiyueSunnyBao&#34; target=&#34;_blank&#34;&gt;Sunney Bao&lt;/a&gt; suggested &lt;a href=&#34;https://colibread.inria.fr/software/mapsembler2/&#34; target=&#34;_blank&#34;&gt;mapsember2&lt;/a&gt; for this purpose. What &lt;code&gt;mapsember2&lt;/code&gt; does is extending the &lt;code&gt;Tdtomato&lt;/code&gt; fasta based on the fastq reads. I see it something like a local reassembly based on some baits.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
conda create -n mapsembler -c bioconda mapsembler2
conda activate mapsembler

run_mapsembler2_pipeline.sh -s tdtomato_cre.fa -r &amp;quot;Sample1_S1_L001_R2_001.fastq.gz Sample1_S1_L002_R2_001.fastq.gz&amp;quot; -t 1 -p cre_tdtomato
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Depending on how many reads you have, it can take long. This is a novaseq run, it took me 2 days to finish running.
After that, in the &lt;code&gt;cre_tdtomato&lt;/code&gt; folder, there is a file named &lt;code&gt;cre_tdtomato_original_k_31_c_5_t_1.fasta&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat cre_tdtomato_original_k_31_c_5_t_1.fasta
&amp;gt;cre
ATGGCCAATTTACTGACCGTACACCAAAATTTGCCTGCATTACCGGTCGATGCAACGAGTGATGAGGTTCGCAAGAACCTGATGGACATGTTCAGGGATCGCCAGGCGTTTTCTGAGCATACCTGGAAAATGCTTCTGTCCGTTTGCCGGTCGTGGGCGGCATGGTGCAAGTTGAATAACCGGAAATGGTTTCCCGCAGAACCTGAAGATGTTCGCGATTATCTTCTATATCTTCAGGCGCGCGGTCTGGCAGTAAAAACTATCCAGCAACATTTGGGCCAGCTAAACATGCTTCATCGTCGGTCCGGGCTGCCACGACCAAGTGACAGCAATGCTGTTTCACTGGTTATGCGGCGGATCCGAAAAGAAAACGTTGATGCCGGTGAACGTGCAAAACAGGCTCTAGCGTTCGAACGCACTGATTTCGACCAGGTTCGTTCACTCATGGAAAATAGCGATCGCTGCCAGGATATACGTAATCTGGCATTTCTGGGGATTGCTTATAACACCCTGTTACGTATAGCCGAAATTGCCAGGATCAGGGTTAAAGATATCTCACGTACTGACGGTGGGAGAATGTTAATCCATATTGGCAGAACGAAAACGCTGGTTAGCACCGCAGGTGTAGAGAAGGCACTTAGCCTGGGGGTAACTAAACTGGTCGAGCGATGGATTTCCGTCTCTGGTGTAGCTGATGATCCGAATAACTACCTGTTTTGCCGGGTCAGAAAAAATGGTGTTGCCGCGCCATCTGCCACCAGCCAGCTATCAACTCGCGCCCTGGAAGGGATTTTTGAAGCAACTCATCGATTGATTTACGGCGCTAAGGATGACTCTGGTCAGAGATACCTGGCCTGGTCTGGACACAGTGCCCGTGTCGGAGCCGCGCGAGATATGGCCCGCGCTGGAGTTTCAATACCGGAGATCATGCAAGCTGGTGGCTGGACCAATGTAAATATTGTCATGAACTATATCCGTAACCTGGATAGTGAAACAGGGGCAATGGTGCGCCTGCTGGAAGATGGCGATTAG
&amp;gt;right_extension_0
ATGGTGCGCCTGCTGGAAGATGGCGATTAGCCATT
&amp;gt;tdtomato
ATGGTGAGCAAGGGCGAGGAGGTCATCAAAGAGTTCATGCGCTTCAAGGTGCGCATGGAGGGCTCCATGAACGGCCACGAGTTCGAGATCGAGGGCGAGGGCGAGGGCCGCCCCTACGAGGGCACCCAGACCGCCAAGCTGAAGGTGACCAAGGGCGGCCCCCTGCCCTTCGCCTGGGACATCCTGTCCCCCCAGTTCATGTACGGCTCCAAGGCGTACGTGAAGCACCCCGCCGACATCCCCGATTACAAGAAGCTGTCCTTCCCCGAGGGCTTCAAGTGGGAGCGCGTGATGAACTTCGAGGACGGCGGTCTGGTGACCGTGACCCAGGACTCCTCCCTGCAGGACGGCACGCTGATCTACAAGGTGAAGATGCGCGGCACCAACTTCCCCCCCGACGGCCCCGTAATGCAGAAGAAGACCATGGGCTGGGAGGCCTCCACCGAGCGCCTGTACCCCCGCGACGGCGTGCTGAAGGGCGAGATCCACCAGGCCCTGAAGCTGAAGGACGGCGGCCACTACCTGGTGGAGTTCAAGACCATCTACATGGCCAAGAAGCCCGTGCAACTGCCCGGCTACTACTACGTGGACACCAAGCTGGACATCACCTCCCACAACGAGGACTACACCATCGTGGAACAGTACGAGCGCTCCGAGGGCCGCCACCACCTGTTCCTGGGGCATGGCACCGGCAGCACCGGCAGCGGCAGCTCCGGCACCGCCTCCTCCGAGGACAACAACATGGCCGTCATCAAAGAGTTCATGCGCTTCAAGGTGCGCATGGAGGGCTCCATGAACGGCCACGAGTTCGAGATCGAGGGCGAGGGCGAGGGCCGCCCCTACGAGGGCACCCAGACCGCCAAGCTGAAGGTGACCAAGGGCGGCCCCCTGCCCTTCGCCTGGGACATCCTGTCCCCCCAGTTCATGTACGGCTCCAAGGCGTACGTGAAGCACCCCGCCGACATCCCCGATTACAAGAAGCTGTCCTTCCCCGAGGGCTTCAAGTGGGAGCGCGTGATGAACTTCGAGGACGGCGGTCTGGTGACCGTGACCCAGGACTCCTCCCTGCAGGACGGCACGCTGATCTACAAGGTGAAGATGCGCGGCACCAACTTCCCCCCCGACGGCCCCGTAATGCAGAAGAAGACCATGGGCTGGGAGGCCTCCACCGAGCGCCTGTACCCCCGCGACGGCGTGCTGAAGGGCGAGATCCACCAGGCCCTGAAGCTGAAGGACGGCGGCCACTACCTGGTGGAGTTCAAGACCATCTACATGGCCAAGAAGCCCGTGCAACTGCCCGGCTACTACTACGTGGACACCAAGCTGGACATCACCTCCCACAACGAGGACTACACCATCGTGGAACAGTACGAGCGCTCCGAGGGCCGCCACCACCTGTTCCTGTACGGCATGGACGAGCTGTACAAGTAA
&amp;gt;left_extension_0
CTTCGTATAGCATACATTATACGAAGTTATCACGCGCCGGCCGGCCTCTAGATTACCGGTCTCGCGAAGCCACCATGCCACCCAAAAAGAAAAGAAAGGTGGGCATGGTGAGCAAGGGCGAGGAGGTCATCAAA
&amp;gt;right_extension_0
CTGTACGGCATGGACGAGCTGTACAAGTAATTCGCGAGTGGCGCGTTAAGTGCAACACGTGAAGGCCGGCCCTGCAGGAATTCGATATCAAGCTTATCGATAATCAACCTCTGGATTACAAAATTTGTGAAAGATTGACTGGTATTCTTAACTATGTTGCTCCTTTTACGCTATGTGGATACGCTGCTTTAATGCCTTTGTATCATGCTATTGCTTCCCGTATGGCTTTCATTTTCTCCTCCTTGTATAAATCCTGGTTGCTGTCTCTTTATGAGGAGTTGTGGCCCGTTGTCAGGCAACGTGGCGTGGTGTGCACTGTGTTTGCTGACGCAACCCCCACTGGTTGGGGCATTGCCACCACCTGTCAGCTCCTTTCCGGGACTTTCGCTTTCCCCCTCCCTATTGCCACGGCGGAACTCATCGCCGCCTGCCTTGCCCGCTGCTGGACA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tdtomato&lt;/code&gt; get extended a lot and &lt;code&gt;Cre&lt;/code&gt; gets only a bit (right_extension_0).
I did a &lt;code&gt;blastn&lt;/code&gt; and want to see what is the sequence that was extended.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/posts_img/blastn.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It aligned to a &lt;code&gt;AAV vector&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I was excited at this step. With Tdtomato extending that much, I should get a lot more counts.&lt;/p&gt;

&lt;p&gt;Unfortunately, after I remake the reference with the extended fasta and do a cellranger count. I still get very few number of cells express &lt;code&gt;tdtomato&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## after reading in the sparse matrix
library(Seurat)
Sample1&amp;lt;- Read10X_h5(filename = &amp;quot;data/cre_tdtomato/Sample1/filtered_feature_bc_matrix.h5&amp;quot;)

&amp;gt; table(Sample1[&amp;quot;Tdtomato&amp;quot;, ] ==0)

FALSE  TRUE 
  154 10783 
&amp;gt; table(Sample1[&amp;quot;Cre&amp;quot;, ] ==0)

FALSE  TRUE 
  195 10742 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This bioinformatics: trails and errors. What else can possibly go wrong? Can you please share your experience?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Align multiple ggplot2 plots by axis</title>
      <link>/post/align-multiple-ggplot2-plots-by-axis/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/align-multiple-ggplot2-plots-by-axis/</guid>
      <description>&lt;p&gt;I used to use &lt;code&gt;cowplot&lt;/code&gt; to align multiple ggplot2 plots but when the x-axis are of different ranges, some extra work is needed to align the axis as well.&lt;/p&gt;
&lt;p&gt;The other day I was reading a &lt;a href=&#34;https://mp.weixin.qq.com/s/V1UiR98K6vy00PwkgkTmvA&#34;&gt;blog post&lt;/a&gt; by &lt;code&gt;GuangChuang Yu&lt;/code&gt; and he exactly tackled this problem. His packages such as &lt;code&gt;ChIPseeker&lt;/code&gt;, &lt;code&gt;ClusterProfiler&lt;/code&gt;, &lt;code&gt;ggtree&lt;/code&gt; are quite popular among the users.&lt;/p&gt;
&lt;p&gt;Some dummy example from his post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
library(ggstance)
library(cowplot)
# devtools::install_github(&amp;quot;YuLab-SMU/treeio&amp;quot;)
# devtools::install_github(&amp;quot;YuLab-SMU/ggtree&amp;quot;)
library(tidytree)
library(ggtree)

no_legend=theme(legend.position=&amp;#39;none&amp;#39;)

d &amp;lt;- group_by(mtcars, cyl) %&amp;gt;% summarize(mean=mean(disp), sd=sd(disp))
d2 &amp;lt;- dplyr::filter(mtcars, cyl != 8) %&amp;gt;% rename(var = cyl)

p1 &amp;lt;- ggplot(d, aes(x=cyl, y=mean)) +
    geom_col(aes(fill=factor(cyl)), width=1) +
    no_legend
p2 &amp;lt;- ggplot(d2, aes(var, disp)) +
    geom_jitter(aes(color=factor(var)), width=.5) +
    no_legend

p3 &amp;lt;- ggplot(filter(d, cyl != 4), aes(mean, cyl)) +
    geom_colh(aes(fill=factor(cyl)), width=.6) +
    coord_flip() + no_legend

pp &amp;lt;- list(p1, p2, p3)
plot_grid(plotlist=pp, ncol=1, align=&amp;#39;v&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-07-align-multiple-ggplot2-plots-by-axis_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;specifying &lt;code&gt;aling=&#39;v&#39;&lt;/code&gt; aligns the plots vertically, but because the axis limits are different the x-axis is not aligned.&lt;/p&gt;
&lt;p&gt;Let’s use &lt;code&gt;coord_cartesian&lt;/code&gt; to expand the xlim without filtering out the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p11&amp;lt;- p1 + coord_cartesian(xlim = c(3,11))
p22&amp;lt;- p2 + coord_cartesian(xlim = c(3,11))
p33&amp;lt;- p3 &amp;lt;- ggplot(filter(d, cyl != 4), aes(cyl, mean)) +
    geom_col(aes(fill=factor(cyl)), width=.6) +
  coord_cartesian(xlim = c(3,11)) +no_legend

pp1 &amp;lt;- list(p11, p22, p33)
plot_grid(plotlist=pp1, ncol=1, align=&amp;#39;v&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-07-align-multiple-ggplot2-plots-by-axis_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This works.&lt;/p&gt;
&lt;p&gt;However, as mentioned in the blog post by &lt;code&gt;GuangChuang Yu&lt;/code&gt;. There are several other cases that this may not be easy to work out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;what if the x-axis is character string rather than continuous digits?&lt;/li&gt;
&lt;li&gt;what if the first plot is not from a dataframe (e.g. a tree object from ggtree)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s use the other example from the blog post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2019-10-31)
tr &amp;lt;- rtree(10)

d1 &amp;lt;- data.frame(
    # only some labels match
    label = c(tr$tip.label[sample(5, 5)], &amp;quot;A&amp;quot;),
    value = sample(1:6, 6))

d2 &amp;lt;- data.frame(
    label = rep(tr$tip.label, 5),
    category = rep(LETTERS[1:5], each=10),
    value = rnorm(50, 0, 3))

g &amp;lt;- ggtree(tr) + geom_tiplab(align=TRUE)
g&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-07-align-multiple-ggplot2-plots-by-axis_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is a tree.&lt;/p&gt;
&lt;p&gt;Make some other dummy dataframe for making a bar plot and a heatmap:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- filter(g, isTip) %&amp;gt;% select(c(label, y))

dd1 &amp;lt;- left_join(d1, d, by=&amp;#39;label&amp;#39;)
dd1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   label value  y
## 1    t4     5 10
## 2    t6     6  9
## 3    t9     2  2
## 4    t2     3  8
## 5    t1     4  1
## 6     A     1 NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dd2 &amp;lt;- left_join(d2, d, by=&amp;#39;label&amp;#39;)
head(dd2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   label category      value  y
## 1    t1        A -3.3159014  1
## 2    t9        A  1.1526652  2
## 3    t2        A  0.9969863  8
## 4    t6        A  3.7986173  9
## 5    t4        A  4.9893312 10
## 6   t10        A -2.1545959  6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# a bar graph
p1 &amp;lt;- ggplot(dd1, aes(y, value)) + geom_col(aes(fill=label)) +
    coord_flip() + theme_tree2() + theme(legend.position=&amp;#39;none&amp;#39;)
 
# a heatmap
p2 &amp;lt;- ggplot(dd2, aes(x=category, y=y)) +
    geom_tile(aes(fill=value)) + scale_fill_viridis_c() +
    theme_tree2() + theme(legend.position=&amp;#39;none&amp;#39;)

cowplot::plot_grid(g, p1, p2, ncol=3, align=&amp;#39;h&amp;#39;,
    labels=LETTERS[1:3], rel_widths = c(1, .5, .8))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-07-align-multiple-ggplot2-plots-by-axis_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The y-axis is not aligned with the tip of the &lt;code&gt;ggtree&lt;/code&gt; output if you read carefully.&lt;/p&gt;
&lt;p&gt;Let’s use the &lt;code&gt;ylim2&lt;/code&gt; function from &lt;code&gt;ggtree&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- p1 + ylim2(g)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## the plot was flipped and the y limits will be applied to x-axis&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- p2 + ylim2(g)

cowplot::plot_grid(g, p1, p2, ncol=3, align=&amp;#39;h&amp;#39;,
    labels=LETTERS[1:3], rel_widths = c(1, .5, .8))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-07-align-multiple-ggplot2-plots-by-axis_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now they are aligned perfectly!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ggtree::ylim2()&lt;/code&gt; and &lt;code&gt;ggtree::xlim2()&lt;/code&gt; can be very useful for other cases. Thanks &lt;code&gt;GuangChuang Yu&lt;/code&gt; for making it!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>add pct_in for each cluster for scRNAseq result table using list column</title>
      <link>/post/add-pct-in-for-each-cluster-for-scrnaseq-result-table-using-list-column/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/add-pct-in-for-each-cluster-for-scrnaseq-result-table-using-list-column/</guid>
      <description>&lt;p&gt;Using nested dataframe and list column has transformed my way of data wrangling in R. For more on this topic, I highly recommend &lt;a href=&#34;https://jennybc.github.io/purrr-tutorial/index.html&#34;&gt;purrr tutorial&lt;/a&gt; from Jenney Bryan.&lt;/p&gt;
&lt;p&gt;In this post, I am going to show you how I use this to solve a problem for adding &lt;code&gt;pct_in&lt;/code&gt; column from the differential scRNAseq result table.&lt;/p&gt;
&lt;p&gt;I am going to use &lt;a href=&#34;https://github.com/immunogenomics/presto&#34;&gt;&lt;code&gt;presto&lt;/code&gt;&lt;/a&gt; for differential gene expression test. &lt;code&gt;presto&lt;/code&gt; performs a fast Wilcoxon rank sum test and auROC analysis. It can be used for differential accessible region test for scATACseq data as well. Because scATACseq data can have over 800k regions in my hand, I found it is much faster than &lt;code&gt;Seurat&lt;/code&gt; and also gives sensible results. Using presto also gives you all the genes/regions without filtering. This is particularly useful if you want to run GSEA which requires all genes as input. see &lt;a href=&#34;https://crazyhottommy.github.io/scRNA-seq-workshop-Fall-2019/scRNAseq_workshop_3.html&#34;&gt;this part&lt;/a&gt; for our scRNAseq workshop.&lt;/p&gt;
&lt;p&gt;Let’s download some scRNAseq example data from &lt;a href=&#34;https://satijalab.org/seurat/v3.1/atacseq_integration_vignette.html&#34; class=&#34;uri&#34;&gt;https://satijalab.org/seurat/v3.1/atacseq_integration_vignette.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -L https://www.dropbox.com/s/3f3p5nxrn5b3y4y/pbmc_10k_v3.rds\?dl\=1 -o pbmc_10k_v3.rds&lt;/code&gt;&lt;/p&gt;
&lt;div id=&#34;read-into-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;read into R&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install_github(&amp;#39;immunogenomics/presto&amp;#39;)
library(presto)
library(Seurat)
library(dplyr)
library(tibble)
library(furrr)
library(tictoc)
pbmc&amp;lt;- readRDS(&amp;quot;~/pbmc_10k_v3.rds&amp;quot;)

head(wilcoxauc(pbmc, &amp;quot;RNA_snn_res.0.4&amp;quot; ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      feature group     avgExpr         logFC statistic       auc
## 1 AL627309.1     0 0.004455649 -0.0001475212   9648856 0.5007586
## 2 AL669831.5     0 0.058653109  0.0155762453   9974323 0.5176497
## 3     FAM87B     0 0.001185081  0.0007726323   9649065 0.5007694
## 4  LINC00115     0 0.023454801 -0.0001696563   9701960 0.5035145
## 5     FAM41C     0 0.025523520  0.0035611306   9745564 0.5057775
## 6 AL645608.3     0 0.000766896  0.0003039512   9642626 0.5004352
##           pval         padj    pct_in    pct_out
## 1 3.450509e-01 4.033191e-01 0.6350267 0.48136646
## 2 7.957294e-12 2.279022e-11 8.3221925 4.58074534
## 3 2.429577e-02 3.743801e-02 0.2005348 0.04658385
## 4 5.546520e-02 8.014953e-02 3.3422460 2.59316770
## 5 1.339544e-03 2.430893e-03 3.5427807 2.34472050
## 6 1.485920e-01 1.932465e-01 0.1336898 0.04658385&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;by default, &lt;code&gt;presto&lt;/code&gt; and &lt;code&gt;Seurat&lt;/code&gt; compare a gene in cells of one group versus all other groups of cells and calculate the
statistics. In the output, you see &lt;code&gt;pct_in&lt;/code&gt; and &lt;code&gt;pct_out&lt;/code&gt; columns which show the percentage of cells express this gene in the &lt;code&gt;in&lt;/code&gt; group and perecentage of cells express this gene in the &lt;code&gt;out&lt;/code&gt; groups. What if you want to know &lt;code&gt;pct_out&lt;/code&gt; in each of the group? How do you add that information to the dataframe? In addtion, you may also want to add the number of cells in each cluster into the dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res&amp;lt;- wilcoxauc(pbmc, &amp;quot;RNA_snn_res.0.4&amp;quot; )

## how many genes in the result?
length(unique(res$feature))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 19089&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## for each group we have the same number of genes
count(res, group) %&amp;gt;% arrange(as.numeric(group))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 x 2
##    group     n
##    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 0     19089
##  2 1     19089
##  3 2     19089
##  4 3     19089
##  5 4     19089
##  6 5     19089
##  7 6     19089
##  8 7     19089
##  9 8     19089
## 10 9     19089
## 11 10    19089
## 12 11    19089
## 13 12    19089&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;get a dataframe for number of cells in each group&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(cell_number&amp;lt;- pbmc@meta.data %&amp;gt;%
  count(RNA_snn_res.0.4) %&amp;gt;%
  dplyr::rename(group = RNA_snn_res.0.4, cell_number = n))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 x 2
##    group cell_number
##    &amp;lt;fct&amp;gt;       &amp;lt;int&amp;gt;
##  1 0            2992
##  2 1            1596
##  3 2            1047
##  4 3             959
##  5 4             592
##  6 5             544
##  7 6             460
##  8 7             383
##  9 8             337
## 10 9             328
## 11 10             74
## 12 11             68
## 13 12             52&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s nest the dataframe by gene&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res_nest&amp;lt;- res %&amp;gt;%
  group_by(feature) %&amp;gt;% 
  tidyr::nest()

res_nest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 19,089 x 2
## # Groups:   feature [19,089]
##    feature    data                                                         
##    &amp;lt;chr&amp;gt;      &amp;lt;S3: vctrs_list_of&amp;gt;                                          
##  1 AL627309.1 0                    , 1                    , 10            …
##  2 AL669831.5 0                   , 1                   , 10              …
##  3 FAM87B     0                    , 1                    , 10            …
##  4 LINC00115  0                    , 1                    , 10            …
##  5 FAM41C     0                   , 1                   , 10              …
##  6 AL645608.3 0                    , 1                    , 10            …
##  7 SAMD11     0                    , 1                    , 10            …
##  8 NOC2L      0                   , 1                   , 10              …
##  9 KLHL17     0                   , 1                   , 10              …
## 10 PLEKHN1    0                    , 1                    , 10            …
## # … with 19,079 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;res_nest&lt;/code&gt; is a nested dataframe with a list column named &lt;code&gt;data&lt;/code&gt;. Let’s check the first entry of this list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- res_nest$data[[1]] %&amp;gt;% arrange(as.numeric(group))
head(df)  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 9
##   group avgExpr     logFC statistic   auc   pval  padj pct_in pct_out
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 0     0.00446 -0.000148  9648856. 0.501 0.345  0.403  0.635   0.481
## 2 1     0.00206 -0.00300   6232089  0.498 0.0916 0.162  0.251   0.587
## 3 2     0.00285 -0.00192   4377551  0.499 0.251  0.364  0.287   0.561
## 4 3     0.00685  0.00255   4067216. 0.501 0.661  0.723  0.626   0.519
## 5 4     0.00650  0.00208   2620733  0.501 0.612  0.719  0.676   0.520
## 6 5     0.00834  0.00401   2422859  0.501 0.492  0.648  0.735   0.518&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can collect the &lt;code&gt;pct_in&lt;/code&gt; for this gene from &lt;code&gt;df&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(df&amp;lt;- df %&amp;gt;% 
  left_join(cell_number, by = c(&amp;quot;group&amp;quot; = &amp;quot;group&amp;quot;)) %&amp;gt;%
  mutate(pct_in_group = paste(group, pct_in, sep= &amp;quot;_&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Column `group` joining character vector and factor, coercing into
## character vector&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 x 11
##    group avgExpr    logFC statistic   auc   pval  padj pct_in pct_out
##    &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 0     0.00446 -1.48e-4  9648856. 0.501 0.345  0.403  0.635   0.481
##  2 1     0.00206 -3.00e-3  6232089  0.498 0.0916 0.162  0.251   0.587
##  3 2     0.00285 -1.92e-3  4377551  0.499 0.251  0.364  0.287   0.561
##  4 3     0.00685  2.55e-3  4067216. 0.501 0.661  0.723  0.626   0.519
##  5 4     0.00650  2.08e-3  2620733  0.501 0.612  0.719  0.676   0.520
##  6 5     0.00834  4.01e-3  2422859  0.501 0.492  0.648  0.735   0.518
##  7 6     0.00816  3.78e-3  2070947  0.502 0.303  0.507  0.870   0.513
##  8 7     0.00245 -2.20e-3  1728031  0.499 0.460  0.685  0.261   0.541
##  9 8     0       -4.73e-3  1524082. 0.497 0.172  0.348  0       0.550
## 10 9     0.00533  7.97e-4  1498956. 0.502 0.333  0.524  0.915   0.516
## 11 10    0.00609  1.55e-3   349088. 0.504 0.333  0.586  1.35    0.524
## 12 11    0       -4.59e-3   316676  0.497 0.546  0.848  0       0.534
## 13 12    0.0295   2.50e-2   247320. 0.507 0.163  0.437  1.92    0.522
## # … with 2 more variables: cell_number &amp;lt;int&amp;gt;, pct_in_group &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# interleave the pct_in and number_in 
pct_in_groups&amp;lt;- df$pct_in
num_in_groups&amp;lt;- df$cell_number
names_pct_in_groups&amp;lt;-  paste(df$group,&amp;quot;pct_in&amp;quot;, sep = &amp;quot;_&amp;quot;)
names_num_in_groups&amp;lt;- paste(df$group, &amp;quot;cell_num&amp;quot;, sep= &amp;quot;_&amp;quot;)
# https://stackoverflow.com/questions/16443260/interleave-lists-in-r
out&amp;lt;- c(rbind(num_in_groups, pct_in_groups))
names(out)&amp;lt;- c(rbind(names_num_in_groups, names_pct_in_groups))
out&amp;lt;- bind_rows(out)
out&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 26
##   `0_cell_num` `0_pct_in` `1_cell_num` `1_pct_in` `2_cell_num` `2_pct_in`
##          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1         2992      0.635         1596      0.251         1047      0.287
## # … with 20 more variables: `3_cell_num` &amp;lt;dbl&amp;gt;, `3_pct_in` &amp;lt;dbl&amp;gt;,
## #   `4_cell_num` &amp;lt;dbl&amp;gt;, `4_pct_in` &amp;lt;dbl&amp;gt;, `5_cell_num` &amp;lt;dbl&amp;gt;,
## #   `5_pct_in` &amp;lt;dbl&amp;gt;, `6_cell_num` &amp;lt;dbl&amp;gt;, `6_pct_in` &amp;lt;dbl&amp;gt;,
## #   `7_cell_num` &amp;lt;dbl&amp;gt;, `7_pct_in` &amp;lt;dbl&amp;gt;, `8_cell_num` &amp;lt;dbl&amp;gt;,
## #   `8_pct_in` &amp;lt;dbl&amp;gt;, `9_cell_num` &amp;lt;dbl&amp;gt;, `9_pct_in` &amp;lt;dbl&amp;gt;,
## #   `10_cell_num` &amp;lt;dbl&amp;gt;, `10_pct_in` &amp;lt;dbl&amp;gt;, `11_cell_num` &amp;lt;dbl&amp;gt;,
## #   `11_pct_in` &amp;lt;dbl&amp;gt;, `12_cell_num` &amp;lt;dbl&amp;gt;, `12_pct_in` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have 13 groups of cells, so we get a tibble of 1 x 26 with number of cells and percentage of cells for each group in each column. We now only need to &lt;code&gt;cbind&lt;/code&gt; this info back to each gene.&lt;/p&gt;
&lt;p&gt;Let’s write a function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;add_pct_in&amp;lt;- function(df, cell_number){
  df&amp;lt;- df %&amp;gt;% 
  left_join(cell_number, by = c(&amp;quot;group&amp;quot; = &amp;quot;group&amp;quot;)) %&amp;gt;%
  mutate(pct_in_group = paste(group, pct_in, sep= &amp;quot;_&amp;quot;))
  
  pct_in_groups&amp;lt;- df$pct_in
  num_in_groups&amp;lt;- df$cell_number
  names_pct_in_groups&amp;lt;-  paste(df$group,&amp;quot;pct_in&amp;quot;, sep = &amp;quot;_&amp;quot;)
  names_num_in_groups&amp;lt;- paste(df$group, &amp;quot;cell_num&amp;quot;, sep= &amp;quot;_&amp;quot;)
  # https://stackoverflow.com/questions/16443260/interleave-lists-in-r
  out&amp;lt;- c(rbind(num_in_groups, pct_in_groups))
  names(out)&amp;lt;- c(rbind(names_num_in_groups, names_pct_in_groups))
  out&amp;lt;- bind_rows(out)
  return(out)
}

## test this function for one gene
add_pct_in(df = res_nest$data[[1]], cell_number = cell_number )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Column `group` joining character vector and factor, coercing into
## character vector&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 26
##   `0_cell_num` `0_pct_in` `1_cell_num` `1_pct_in` `10_cell_num` `10_pct_in`
##          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1         2992      0.635         1596      0.251            74        1.35
## # … with 20 more variables: `11_cell_num` &amp;lt;dbl&amp;gt;, `11_pct_in` &amp;lt;dbl&amp;gt;,
## #   `12_cell_num` &amp;lt;dbl&amp;gt;, `12_pct_in` &amp;lt;dbl&amp;gt;, `2_cell_num` &amp;lt;dbl&amp;gt;,
## #   `2_pct_in` &amp;lt;dbl&amp;gt;, `3_cell_num` &amp;lt;dbl&amp;gt;, `3_pct_in` &amp;lt;dbl&amp;gt;,
## #   `4_cell_num` &amp;lt;dbl&amp;gt;, `4_pct_in` &amp;lt;dbl&amp;gt;, `5_cell_num` &amp;lt;dbl&amp;gt;,
## #   `5_pct_in` &amp;lt;dbl&amp;gt;, `6_cell_num` &amp;lt;dbl&amp;gt;, `6_pct_in` &amp;lt;dbl&amp;gt;,
## #   `7_cell_num` &amp;lt;dbl&amp;gt;, `7_pct_in` &amp;lt;dbl&amp;gt;, `8_cell_num` &amp;lt;dbl&amp;gt;,
## #   `8_pct_in` &amp;lt;dbl&amp;gt;, `9_cell_num` &amp;lt;dbl&amp;gt;, `9_pct_in` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because we are going to apply this function to over 10,000 genes, I am going to use the parallized &lt;code&gt;purrr&lt;/code&gt;: &lt;code&gt;furrr&lt;/code&gt;.
&lt;a href=&#34;https://github.com/DavisVaughan/furrr&#34; class=&#34;uri&#34;&gt;https://github.com/DavisVaughan/furrr&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plan(multiprocess, workers = 8)

# this will start 8 workers, but each worker will consume 20Mb memory 
print(object.size(res), units= &amp;quot;Mb&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 20 Mb&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic()
info&amp;lt;- furrr::future_map_dfr(res_nest$data, ~ add_pct_in(df= .x, cell_number = cell_number)) 
toc()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 9.007 sec elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(info)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 26
##   `0_cell_num` `0_pct_in` `1_cell_num` `1_pct_in` `10_cell_num` `10_pct_in`
##          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1         2992      0.635         1596     0.251             74        1.35
## 2         2992      8.32          1596     3.57              74       20.3 
## 3         2992      0.201         1596     0.0627            74        0   
## 4         2992      3.34          1596     2.26              74        9.46
## 5         2992      3.54          1596     1.63              74        9.46
## 6         2992      0.134         1596     0                 74        0   
## # … with 20 more variables: `11_cell_num` &amp;lt;dbl&amp;gt;, `11_pct_in` &amp;lt;dbl&amp;gt;,
## #   `12_cell_num` &amp;lt;dbl&amp;gt;, `12_pct_in` &amp;lt;dbl&amp;gt;, `2_cell_num` &amp;lt;dbl&amp;gt;,
## #   `2_pct_in` &amp;lt;dbl&amp;gt;, `3_cell_num` &amp;lt;dbl&amp;gt;, `3_pct_in` &amp;lt;dbl&amp;gt;,
## #   `4_cell_num` &amp;lt;dbl&amp;gt;, `4_pct_in` &amp;lt;dbl&amp;gt;, `5_cell_num` &amp;lt;dbl&amp;gt;,
## #   `5_pct_in` &amp;lt;dbl&amp;gt;, `6_cell_num` &amp;lt;dbl&amp;gt;, `6_pct_in` &amp;lt;dbl&amp;gt;,
## #   `7_cell_num` &amp;lt;dbl&amp;gt;, `7_pct_in` &amp;lt;dbl&amp;gt;, `8_cell_num` &amp;lt;dbl&amp;gt;,
## #   `8_pct_in` &amp;lt;dbl&amp;gt;, `9_cell_num` &amp;lt;dbl&amp;gt;, `9_pct_in` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## cbind back to the nested dataframe
bind_cols(res_nest, info) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 28
## # Groups:   feature [6]
##   feature data  `0_cell_num` `0_pct_in` `1_cell_num` `1_pct_in`
##   &amp;lt;chr&amp;gt;   &amp;lt;S3:&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1 AL6273… 0   …         2992      0.635         1596     0.251 
## 2 AL6698… 0   …         2992      8.32          1596     3.57  
## 3 FAM87B  0   …         2992      0.201         1596     0.0627
## 4 LINC00… 0   …         2992      3.34          1596     2.26  
## 5 FAM41C  0   …         2992      3.54          1596     1.63  
## 6 AL6456… 0   …         2992      0.134         1596     0     
## # … with 22 more variables: `10_cell_num` &amp;lt;dbl&amp;gt;, `10_pct_in` &amp;lt;dbl&amp;gt;,
## #   `11_cell_num` &amp;lt;dbl&amp;gt;, `11_pct_in` &amp;lt;dbl&amp;gt;, `12_cell_num` &amp;lt;dbl&amp;gt;,
## #   `12_pct_in` &amp;lt;dbl&amp;gt;, `2_cell_num` &amp;lt;dbl&amp;gt;, `2_pct_in` &amp;lt;dbl&amp;gt;,
## #   `3_cell_num` &amp;lt;dbl&amp;gt;, `3_pct_in` &amp;lt;dbl&amp;gt;, `4_cell_num` &amp;lt;dbl&amp;gt;,
## #   `4_pct_in` &amp;lt;dbl&amp;gt;, `5_cell_num` &amp;lt;dbl&amp;gt;, `5_pct_in` &amp;lt;dbl&amp;gt;,
## #   `6_cell_num` &amp;lt;dbl&amp;gt;, `6_pct_in` &amp;lt;dbl&amp;gt;, `7_cell_num` &amp;lt;dbl&amp;gt;,
## #   `7_pct_in` &amp;lt;dbl&amp;gt;, `8_cell_num` &amp;lt;dbl&amp;gt;, `8_pct_in` &amp;lt;dbl&amp;gt;,
## #   `9_cell_num` &amp;lt;dbl&amp;gt;, `9_pct_in` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can unnest the dataframe&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_cols(res_nest, info) %&amp;gt;% 
  tidyr::unnest() %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `cols` is now required.
## Please use `cols = c(data)`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 36
## # Groups:   feature [1]
##   feature group avgExpr    logFC statistic   auc   pval  padj pct_in
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 AL6273… 0     0.00446 -1.48e-4  9648856. 0.501 0.345  0.403  0.635
## 2 AL6273… 1     0.00206 -3.00e-3  6232089  0.498 0.0916 0.162  0.251
## 3 AL6273… 10    0.00609  1.55e-3   349088. 0.504 0.333  0.586  1.35 
## 4 AL6273… 11    0       -4.59e-3   316676  0.497 0.546  0.848  0    
## 5 AL6273… 12    0.0295   2.50e-2   247320. 0.507 0.163  0.437  1.92 
## 6 AL6273… 2     0.00285 -1.92e-3  4377551  0.499 0.251  0.364  0.287
## # … with 27 more variables: pct_out &amp;lt;dbl&amp;gt;, `0_cell_num` &amp;lt;dbl&amp;gt;,
## #   `0_pct_in` &amp;lt;dbl&amp;gt;, `1_cell_num` &amp;lt;dbl&amp;gt;, `1_pct_in` &amp;lt;dbl&amp;gt;,
## #   `10_cell_num` &amp;lt;dbl&amp;gt;, `10_pct_in` &amp;lt;dbl&amp;gt;, `11_cell_num` &amp;lt;dbl&amp;gt;,
## #   `11_pct_in` &amp;lt;dbl&amp;gt;, `12_cell_num` &amp;lt;dbl&amp;gt;, `12_pct_in` &amp;lt;dbl&amp;gt;,
## #   `2_cell_num` &amp;lt;dbl&amp;gt;, `2_pct_in` &amp;lt;dbl&amp;gt;, `3_cell_num` &amp;lt;dbl&amp;gt;,
## #   `3_pct_in` &amp;lt;dbl&amp;gt;, `4_cell_num` &amp;lt;dbl&amp;gt;, `4_pct_in` &amp;lt;dbl&amp;gt;,
## #   `5_cell_num` &amp;lt;dbl&amp;gt;, `5_pct_in` &amp;lt;dbl&amp;gt;, `6_cell_num` &amp;lt;dbl&amp;gt;,
## #   `6_pct_in` &amp;lt;dbl&amp;gt;, `7_cell_num` &amp;lt;dbl&amp;gt;, `7_pct_in` &amp;lt;dbl&amp;gt;,
## #   `8_cell_num` &amp;lt;dbl&amp;gt;, `8_pct_in` &amp;lt;dbl&amp;gt;, `9_cell_num` &amp;lt;dbl&amp;gt;,
## #   `9_pct_in` &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are possiblely other easier ways to achieve the same result. Please share your thoughts in the comments!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The end of 2019</title>
      <link>/post/the-end-of-2019/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/the-end-of-2019/</guid>
      <description>&lt;p&gt;It is the end of 2019. How time flies! It is a good time to reflect what I have
achieved during the past year and what to look forward in 2020. I wrote a post for
2018 &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/the-end-of-2018/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.
I am not the only one who has impostor syndrome :) It is important to celebrate your
small successes/achievements by writing them down.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;I taught a snakemake and scRNAseq workshop during the FAS informatics 2-week &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/talk/2019-harvard-fas-workshop/&#34; target=&#34;_blank&#34;&gt;nanocourse&lt;/a&gt;. I love teaching biologists computing skills that I have learned from scratch. Nowadays, almost &lt;a href=&#34;https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002050&#34; target=&#34;_blank&#34;&gt;every biology is computational biology&lt;/a&gt;. I also helped/taught lab members in Dulac lab with programming.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I had my first R package &lt;a href=&#34;https://github.com/crazyhottommy/scclusteval&#34; target=&#34;_blank&#34;&gt;scclusteval&lt;/a&gt; for estimating cluster stability in single-cell RNAseq data in github and am writing it up for a small paper. I had some changes that have not been committed to github yet. I presented it in the &lt;a href=&#34;http://bioc2019.bioconductor.org/&#34; target=&#34;_blank&#34;&gt;2019 bioconductor annual meeting&lt;/a&gt; which was held in NYC. I met many wonderful tweeps during the conference including &lt;a href=&#34;https://twitter.com/nomad421&#34; target=&#34;_blank&#34;&gt;Rob Patro&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/mikelove&#34; target=&#34;_blank&#34;&gt;Mike Love&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/anshulkundaje&#34; target=&#34;_blank&#34;&gt;Ansul kundaje&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/QianLiu28878838&#34; target=&#34;_blank&#34;&gt;Qian liu&lt;/a&gt; (congrats for the new professorship!), &lt;a href=&#34;https://profiles.umassmed.edu/display/129880&#34; target=&#34;_blank&#34;&gt;Lihua Zhu&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/davetang31&#34; target=&#34;_blank&#34;&gt;Dave Tang&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/k3yavi&#34; target=&#34;_blank&#34;&gt;Avi Srivastava&lt;/a&gt; and many others. Thanks bioconductor for the travel award! bioconductor 2020 will be in local Boston, so I will see everyone here!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;My first co-first author computational paper is still under review after revision. I have my fingers crossed for the reviewers&amp;rsquo; comments back. It has tons of experimental data and computational analysis of both in-house and public data. You can have a look in biorxiv &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/507202v1&#34; target=&#34;_blank&#34;&gt;https://www.biorxiv.org/content/10.1101/507202v1&lt;/a&gt;. I promise to update the README and pipeline once it is accepted :) &lt;a href=&#34;https://github.com/crazyhottommy/pyflow-ChIPseq&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/pyflow-ChIPseq&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I started working on scATACseq in March 2019. It is a brand new field and I have learned quite a bit during the journey. I learned the sparsity of the matrix (more sparse than scRNAseq given the nature of the experiment: we only 2 copies of diploid DNA). I wrote some &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/#posts&#34; target=&#34;_blank&#34;&gt;blog posts&lt;/a&gt; on it. I am developing an R/bioconductor package to deal with scATACseq data &lt;a href=&#34;https://github.com/crazyhottommy/scATACutils&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/scATACutils&lt;/a&gt;. I plan to add more functions and improve the documentations. I presented it in the cold spring harbor &lt;a href=&#34;https://meetings.cshl.edu/meetings.aspx?meet=SINGLE&amp;amp;year=19&#34; target=&#34;_blank&#34;&gt;Single Cell Analyses&lt;/a&gt; meeting.It is amazing to see the development of the single-cell field in the past 10 years! I met some awesome people there including &lt;a href=&#34;https://twitter.com/LGMartelotto&#34; target=&#34;_blank&#34;&gt;Luciano Martelotto&lt;/a&gt; and got to see some of my old MD Anderson Colleagues.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I said I would start learning some deep learning in 2019. That did not happen much. Instead, I started watching some linear algebra courses by MIT Gilbert Strang &lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/index.htm&#34; target=&#34;_blank&#34;&gt;18.06&lt;/a&gt; and &lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/index.htm&#34; target=&#34;_blank&#34;&gt;18.065&lt;/a&gt;. I have finished watching 70% of the videos and really enjoyed them. I got a much better idea of matrix dimentionality (along with space and subspace) and matrix factorization(e.g. SVD). I highly recommend youtube videos from 3blue1brown: &lt;a href=&#34;https://www.3blue1brown.com/essence-of-linear-algebra-page&#34; target=&#34;_blank&#34;&gt;Essense of linear algebra&lt;/a&gt; as well. Thanks &lt;a href=&#34;https://twitter.com/zhiiiyang&#34; target=&#34;_blank&#34;&gt;Yi Zhang&lt;/a&gt; for recommending. At the same time, I slowly picked up &lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34; target=&#34;_blank&#34;&gt;Deep learning with R&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I started &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/run-rstudio-server-with-singularity-on-hpc/&#34; target=&#34;_blank&#34;&gt;using docker and singularity&lt;/a&gt; for reproducible computing. It is a life-saver for me. Thanks Nathan for helping me along the way.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I finally met &lt;a href=&#34;https://twitter.com/JasonWilliamsNY&#34; target=&#34;_blank&#34;&gt;Jason Willimas&lt;/a&gt; in person together with &lt;a href=&#34;https://twitter.com/dccc_phd&#34; target=&#34;_blank&#34;&gt;Damien&lt;/a&gt;. Jason is a very nice person. Next time we will treat you when you are in Boston again. I am sure this is in the right category of my success list :)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I am grateful that I am in a such supporting position and I have been learning new things. Thanks everyone who has helped me along the way.&lt;/p&gt;

&lt;p&gt;In the coming 2020, I should&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;learn more stats. I registered one class from Harvard Extension school and will see how it goes. Lacking statistics background hurts me.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;do better in data and project management. I will start using &lt;a href=&#34;https://pypi.org/project/dtool/&#34; target=&#34;_blank&#34;&gt;dtool&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;write some papers up. A good paper is a finished paper. I hear you.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;try to be a better human, a better husband and father and then a better researcher.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Mixing mouse and human 10x single cell RNAseq data</title>
      <link>/post/mixing-mouse-and-human-10x-single-cell-rnaseq-data/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/mixing-mouse-and-human-10x-single-cell-rnaseq-data/</guid>
      <description>&lt;p&gt;In a typical “barnyard” experiment in which cells from different species are mixed before loading to the 10x controller, the identification of the species of origin after mapping/counting with the hybrid reference is a problem. People tend to use the ratio of reads mapped to each reference genome to determine which species a cell is from.&lt;/p&gt;
&lt;p&gt;In this paper &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/630087v1.full&#34; class=&#34;uri&#34;&gt;https://www.biorxiv.org/content/10.1101/630087v1.full&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To deconvolute species, detect doublets and low quality cells, the mixed-species mapped data was used. Cells for which &amp;gt;70% of the reads mapped to only one species were assigned to the corresponding species. The remaining cells (those for which &amp;lt;70% of the reads mapped to only one species) were removed from the downstream analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;kallisto bustool &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt; uses 90% as a cutoff.&lt;/p&gt;
&lt;p&gt;However, how to choose this cutoff is subjective. In this blog post, I will mix a mouse and a human 10x single cell RNAseq dataset in silicon and then map to the hybrid transriptome. We have the ground truth of which cell comes from which species so we can investigate the mapping rate.&lt;/p&gt;
&lt;div id=&#34;download-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Download data&lt;/h3&gt;
&lt;p&gt;Download 1k pbmc data and 1k mouse brain data from 10x website.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cd /n/holylfs/LABS/informatics/mtang/projects/dj/10x_mouse_human_mixing
wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/neuron_1k_v3/neuron_1k_v3_fastqs.tar

wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v3/pbmc_1k_v3_fastqs.tar

## after tar xvf
ls neuron_1k_v3_fastqs/
neuron_1k_v3_S1_L001_I1_001.fastq.gz  neuron_1k_v3_S1_L001_R2_001.fastq.gz  neuron_1k_v3_S1_L002_R1_001.fastq.gz
neuron_1k_v3_S1_L001_R1_001.fastq.gz  neuron_1k_v3_S1_L002_I1_001.fastq.gz  neuron_1k_v3_S1_L002_R2_001.fastq.gz

ls pbmc_1k_v3_fastqs/
pbmc_1k_v3_S1_L001_I1_001.fastq.gz  pbmc_1k_v3_S1_L001_R2_001.fastq.gz  pbmc_1k_v3_S1_L002_R1_001.fastq.gz
pbmc_1k_v3_S1_L001_R1_001.fastq.gz  pbmc_1k_v3_S1_L002_I1_001.fastq.gz  pbmc_1k_v3_S1_L002_R2_001.fastq.gz&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;add-species-barcode-to-the-r1-fastq&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;add species barcode to the R1 fastq&lt;/h3&gt;
&lt;p&gt;Different experiment could have barcode collisions, let’s add additional barcode in front of the original cell barcode.&lt;/p&gt;
&lt;p&gt;save the below as a &lt;code&gt;add_species_barcode.sh&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;This script adds a 8 base pair barcode in front of the R1 reads (16bp cell barcode + 12 bp umi for 10x version3) and some dummy high quality score (I) to the quality line.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;#! /bin/bash
set -euo pipefail

zcat $1 |  awk -v barcode=&amp;quot;$2&amp;quot; &amp;#39;NR%4 == 2 {$0=barcode$0} NR%4==0 {$0=&amp;quot;IIIIIIII&amp;quot;$0} {print}&amp;#39; | gzip  &amp;gt; $3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am adding &lt;code&gt;AAAAAAAA&lt;/code&gt; and &lt;code&gt;TTTTTTTT&lt;/code&gt; to mouse and human data, respectively.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chmod u+x add_species_barcode.sh

./add_species_barcode.sh neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001.fastq.gz AAAAAAAA neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz


./add_species_barcode.sh neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001.fastq.gz AAAAAAAA neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz


./add_species_barcode.sh pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001.fastq.gz TTTTTTTT pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz


./add_species_barcode.sh pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001.fastq.gz TTTTTTTT pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-a-hybrid-index-for-kallisto.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;build a hybrid index for kallisto.&lt;/h3&gt;
&lt;p&gt;kallisto uses cDNA for indexing.&lt;/p&gt;
&lt;p&gt;Note &lt;a href=&#34;https://www.kallistobus.tools/kb_transcriptome_index.html&#34;&gt;&lt;code&gt;kb-python&lt;/code&gt;&lt;/a&gt; uses genomics DNA and gtf file for making reference (it will extract the cDNA from genomic DNA based on gtf file). I tested &lt;code&gt;kb-python&lt;/code&gt; for a single species experiment and it worked well and saves you doing all the steps. However, &lt;code&gt;kb ref&lt;/code&gt; requires the fasta and gtf files to be merged for creating the hybrid reference. I may try it next time.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;## download the cDNA for mouse and human
wget ftp://ftp.ensembl.org/pub/release-96/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz
wget ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz

## download the gtf files
wget ftp://ftp.ensembl.org/pub/release-96/gtf/mus_musculus/Mus_musculus.GRCm38.96.gtf.gz
wget ftp://ftp.ensembl.org/pub/release-96/gtf/homo_sapiens/Homo_sapiens.GRCh38.96.gtf.gz

kallisto index -i GRCh38_GRCm38/GRCh38_GRCm38_96.idx Homo_sapiens.GRCh38.cdna.all.fa.gz Mus_musculus.GRCm38.cdna.all.fa.gz&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;kallisto-count-at-transcript-level&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;kallisto count at transcript level&lt;/h4&gt;
&lt;p&gt;Note 10x V2 R1 is 16bp cell barcode + 10 bp umi, V3 R1 is 16 bp cell barcode + 12 bp umi.&lt;/p&gt;
&lt;p&gt;See my previous post &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/understand-10x-scrnaseq-and-scatac-fastqs/&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.rbind.io/post/understand-10x-scrnaseq-and-scatac-fastqs/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;
kallisto bus -i /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38_96.idx -o mouse_human_kallisto_out -x 0,0,24:0,24,36:1,0,0 -t8 \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R2_001.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R2_001.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R2_001.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R2_001.fastq.gz

[index] k-mer length: 31
[index] number of targets: 307,242
[index] number of k-mers: 208,670,671
[index] number of equivalence classes: 1,276,238
[quant] will process sample 1: neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz
                               neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R2_001.fastq.gz
[quant] will process sample 2: neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz
                               neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R2_001.fastq.gz
[quant] will process sample 3: pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz
                               pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R2_001.fastq.gz
[quant] will process sample 4: pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz
                               pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R2_001.fastq.gz
[quant] finding pseudoalignments for the reads ... done
[quant] processed 159,504,118 reads, 97,750,679 reads pseudoaligned&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bustools-count-at-gene-level&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;bustools count at gene level&lt;/h3&gt;
&lt;p&gt;we need a transcript to gene mapping tsv file making from gtf file. I could not find the &lt;code&gt;t2g.py&lt;/code&gt; script mentioned in the &lt;a href=&#34;https://www.kallistobus.tools/documentation&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;make a transcript to gene mapping file using unix command line. also read my previous blog post: &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/how-to-make-a-transcript-to-gene-mapping-file/&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.rbind.io/post/how-to-make-a-transcript-to-gene-mapping-file/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;zcat Homo_sapiens.GRCh38.96.gtf.gz | grep -v &amp;quot;#&amp;quot; | awk &amp;#39;$3==&amp;quot;transcript&amp;quot;&amp;#39; | cut -f9 | tr -s &amp;quot;;&amp;quot; &amp;quot; &amp;quot; | awk -v OFS=&amp;quot;\t&amp;quot; &amp;#39;{print$6&amp;quot;\t&amp;quot;$2&amp;quot;\t&amp;quot;$10}&amp;#39; | sort | uniq |  sed &amp;#39;s/\&amp;quot;//g&amp;#39; &amp;gt; Homo_sapiens.GRCh38.96.tsv


zcat Mus_musculus.GRCm38.96.gtf.gz | grep -v &amp;quot;#&amp;quot; | awk &amp;#39;$3==&amp;quot;transcript&amp;quot;&amp;#39; | cut -f9 | tr -s &amp;quot;;&amp;quot; &amp;quot; &amp;quot; | awk -v OFS=&amp;quot;\t&amp;quot; &amp;#39;{print$6&amp;quot;\t&amp;quot;$2&amp;quot;\t&amp;quot;$10}&amp;#39; | sort | uniq |  sed &amp;#39;s/\&amp;quot;//g&amp;#39; &amp;gt; Mus_musculus.GRCm38.96.tsv

## merge the tsv 
cat Homo_sapiens.GRCh38.96.tsv Mus_musculus.GRCm38.96.tsv &amp;gt; GRCh38_GRCm38.96.tsv&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;correct-to-the-whitelist-and-bustools-count-at-gene-level&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;correct to the whitelist and bustools count at gene level&lt;/h3&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;wget https://github.com/BUStools/getting_started/releases/download/species_mixing/10xv3_whitelist.txt

wc -l 10xv3_whitelist.txt
6794880 10xv3_whitelist.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are valid 68k cell barcodes from 10x. we added the species barcode in front of them and use bustool to correct for sequencing errors.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# add the same species barcode to it.
cat 10xv3_whitelist.txt | awk &amp;#39;{print &amp;quot;AAAAAAAA&amp;quot;$0}&amp;#39; &amp;gt; whitelist1.txt
cat 10xv3_whitelist.txt | awk &amp;#39;{print &amp;quot;TTTTTTTT&amp;quot;$0}&amp;#39; &amp;gt; whitelist2.txt
cat whitelist1.txt whitelist2.txt &amp;gt; whitelist.txt

mkdir tmp genecount

bustools correct -w whitelist.txt -p mouse_human_kallisto_out/output.bus | \
bustools sort -T tmp/ -t 4 -p - | \
bustools count -o genecount/genes \
-g /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38.96.tsv \
-e mouse_human_kallisto_out/matrix.ec -t mouse_human_kallisto_out/transcripts.txt --genecounts -

Found 13589760 barcodes in the whitelist

Number of hamming dist 1 barcodes = 461228268
Processed 97750679 bus records
In whitelist = 94311259
Corrected = 329059
Uncorrected = 3110361
Read in 94640318 BUS records&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; it is not working!! 0 genes were mapped when I checked the &lt;code&gt;genes.genes.txt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The devil is that &lt;code&gt;kallisto&lt;/code&gt; infers the transcript id from the &lt;code&gt;cDNA&lt;/code&gt; fasta file which contains the &lt;code&gt;.2&lt;/code&gt; version number, but in the gtf file the version number is in the &lt;code&gt;transcript_version 2&lt;/code&gt; entry.&lt;/p&gt;
&lt;p&gt;The easiest way is to remove the version number in the &lt;code&gt;transcript.txt&lt;/code&gt; file from output.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# make a backup
cp transcripts.txt transcripts.bc.txt

# check how the version number look like for all genes
cat transcripts.txt | cut -d. -f2 | sort | uniq
1
10
11
12
13
14
15
16
17
2
3
4
5
6
7
8
9

cat transcripts.txt | sed -r &amp;#39;s/\.[0-9]?//&amp;#39; &amp;gt; transcript2.txt

## rerun bustool but feeding the transcript2.txt
rm -rf genecount/*

bustools correct -w whitelist.txt -p mouse_human_kallisto_out/output.bus | \
bustools sort -T tmp/ -t 4 -p - | \
bustools count -o genecount/genes \
-g /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38.96.tsv \
-e mouse_human_kallisto_out/matrix.ec -t mouse_human_kallisto_out/transcript2.txt --genecounts -&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;alternative-ways&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Alternative ways&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The R package &lt;a href=&#34;https://github.com/BUStools/BUSpaRse/blob/master/R/tr2g.R&#34;&gt;BUSpaRse&lt;/a&gt; has a function to take care of that to make a transcript to gene mapping file from cDNA fasta. &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34; class=&#34;uri&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BUSpaRse)
tr2g &amp;lt;- transcript2gene(fasta_file = c(&amp;quot;./data/hs_cdna.fa.gz&amp;quot;, &amp;quot;./data/mm_cdna.fa.gz&amp;quot;),
                        kallisto_out_path = &amp;quot;./output/out_hgmm1k&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;kb-python&lt;/code&gt; command &lt;code&gt;kb ref&lt;/code&gt; takes &lt;strong&gt;genomic DNA fasta&lt;/strong&gt; and gtf files and makes the index and a transcript to gene mapping file on the fly.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;load-in-to-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;load in to R&lt;/h3&gt;
&lt;p&gt;following &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34; class=&#34;uri&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BUSpaRse)
library(tidyverse)
library(DropletUtils)
library(Matrix)
library(Seurat)

res_mat &amp;lt;- read_count_output(&amp;quot;~/Downloads/genecount&amp;quot;,name = &amp;quot;genes&amp;quot;, tcc = FALSE)

dim(res_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  71600 731356&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;remove some of the empty droplets&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tot_counts &amp;lt;- Matrix::colSums(res_mat)
summary(tot_counts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##      0.00      1.00      1.00     34.89      5.00 142612.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compute barcode rank from Dropletutils
bc_rank &amp;lt;- barcodeRanks(res_mat)

qplot(bc_rank$total, bc_rank$rank, geom = &amp;quot;line&amp;quot;) +
  geom_vline(xintercept = bc_rank$knee, color = &amp;quot;blue&amp;quot;, linetype = 2) +
  geom_vline(xintercept = bc_rank$inflection, color = &amp;quot;green&amp;quot;, linetype = 2) +
  annotate(&amp;quot;text&amp;quot;, y = 1000, x = 1.5 * c(bc_rank$knee, bc_rank$inflection),
           label = c(&amp;quot;knee&amp;quot;, &amp;quot;inflection&amp;quot;), color = c(&amp;quot;blue&amp;quot;, &amp;quot;green&amp;quot;)) +
  scale_x_log10() +
  scale_y_log10() +
  labs(y = &amp;quot;Barcode rank&amp;quot;, x = &amp;quot;Total UMI count&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-the-cells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;filter the cells&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Filter the matrix
res_mat &amp;lt;- res_mat[, tot_counts &amp;gt; bc_rank$inflection]
dim(res_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 71600  2375&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we get around 2000 cells.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gene_species &amp;lt;- ifelse(str_detect(rownames(res_mat), &amp;quot;^ENSMUSG&amp;quot;), &amp;quot;mouse&amp;quot;, &amp;quot;human&amp;quot;)
mouse_inds &amp;lt;- gene_species == &amp;quot;mouse&amp;quot;
human_inds &amp;lt;- gene_species == &amp;quot;human&amp;quot;
# mark cells as mouse or human
cell_species &amp;lt;- tibble(n_mouse_umi = Matrix::colSums(res_mat[mouse_inds,]),
                       n_human_umi = Matrix::colSums(res_mat[human_inds,]),
                       tot_umi = Matrix::colSums(res_mat),
                       prop_mouse = n_mouse_umi / tot_umi,
                       prop_human = n_human_umi / tot_umi)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ground-truth&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ground truth&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## FALSE  TRUE 
##  1169  1206&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## FALSE  TRUE 
##  1206  1169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have 1206 mouse cells and 1169 human cells&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_species&amp;lt;- cell_species %&amp;gt;% 
  mutate(ground_truth = case_when(
    str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) ~ &amp;quot;mouse&amp;quot;,
    str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) ~ &amp;quot;human&amp;quot;
  )) 

p1&amp;lt;- ggplot(cell_species, aes(x = ground_truth, y = prop_mouse)) +
  geom_boxplot(aes(color = ground_truth))

p2&amp;lt;- ggplot(cell_species, aes(x = ground_truth, y = prop_human)) +
  geom_boxplot(aes(color = ground_truth))

p&amp;lt;- cowplot::plot_grid(
  p1 + theme(legend.position=&amp;quot;none&amp;quot;),
  p2 + theme(legend.position=&amp;quot;none&amp;quot;),
  align = &amp;#39;vh&amp;#39;)

## add back the legend
legend &amp;lt;- cowplot::get_legend(
  # create some space to the left of the legend
  p1 + theme(legend.box.margin = margin(0, 0, 0, 12))
)

# add the legend to the row we made earlier. Give it one-third of 
# the width of one plot (via rel_widths).
cowplot::plot_grid(p, legend, rel_widths = c(2, .4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;minimal and maximal proportion for mapping rate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# min 95%
cell_species$prop_human[cell_species$ground_truth == &amp;quot;human&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9505135 0.9994325&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# max 5%
cell_species$prop_mouse[cell_species$ground_truth == &amp;quot;human&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0005675369 0.0494864613&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# min 97%
cell_species$prop_mouse[cell_species$ground_truth == &amp;quot;mouse&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9743096 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# max 2%
cell_species$prop_human[cell_species$ground_truth == &amp;quot;mouse&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00000000 0.02569043&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;assign species of origin by the proportion&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_species&amp;lt;- cell_species %&amp;gt;% 
  mutate(ground_truth = case_when(
    str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) ~ &amp;quot;mouse&amp;quot;,
    str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) ~ &amp;quot;human&amp;quot;
  )) %&amp;gt;%
  mutate(species = case_when(
    prop_mouse &amp;gt; 0.9 ~ &amp;quot;mouse&amp;quot;,
    prop_human &amp;gt; 0.9 ~ &amp;quot;human&amp;quot;,
    TRUE ~ &amp;quot;mixed&amp;quot;
  ))

table(cell_species$ground_truth, cell_species$species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         human mouse
##   human  1169     0
##   mouse     0  1206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes a 100% match as expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seurat-for-dimension-reduction-and-visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Seurat for dimension reduction and visualization&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seu &amp;lt;- CreateSeuratObject(res_mat, min.cells = 3) %&amp;gt;% 
  NormalizeData(verbose = FALSE) %&amp;gt;% 
  ScaleData(verbose = FALSE) %&amp;gt;% 
  FindVariableFeatures(verbose = FALSE)

seu &amp;lt;- AddMetaData(seu, metadata = cell_species$ground_truth, col.name = &amp;quot;species&amp;quot;)
seu &amp;lt;- RunPCA(seu, verbose = FALSE, npcs = 30)
seu &amp;lt;- RunTSNE(seu, dims = 1:20, check_duplicates = FALSE)
DimPlot(seu, reduction = &amp;quot;pca&amp;quot;, pt.size = 0.5, group.by = &amp;quot;species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(seu, reduction = &amp;quot;tsne&amp;quot;, pt.size = 0.5, group.by = &amp;quot;species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-19-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;conclusion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using ratio of mapped reads for each cell to identify the cell of origin works pretty well for mouse and human mixtures. what if we use a more close species to human say chimpanzee or monkeys? Also, in a real experiment, one may have doublets from different species.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mapping ratio is so drasticially different so a much smaller cutoff can still seperate the sepecies very well. This could be due to the cell type difference. It will be interesting to do the same experiment but with human pbmc and mouse pbmc cells.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I used the hybrid reference for mapping. How it will look like if I map the human cells with the mouse reference or map the mouse cells with the human reference?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling single cell RNAseq data with multinomial distribution </title>
      <link>/post/modeling-single-cell-rnaseq-data-with-multinomial-distribution/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/modeling-single-cell-rnaseq-data-with-multinomial-distribution/</guid>
      <description>&lt;p&gt;I was reading &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/574574v1&#34;&gt;Feature Selection and Dimension Reduction for Single Cell RNA-Seq based on a Multinomial Model&lt;/a&gt;. In the paper, the authors model the scRNAseq counts using a multinomial distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/multinomial.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I was using negative binomial distribution for modeling in my last &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/negative-bionomial-distribution-in-single-cell-rnaseq/&#34;&gt;post&lt;/a&gt;, so I asked the question on twitter:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
for modeling RNAseq counts, what&#39;s the difference/advantages using negative binomial and multinomial distribution?
&lt;/p&gt;
— Ming Tang (&lt;span class=&#34;citation&#34;&gt;@tangming2005&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/tangming2005/status/1199340525188349952?ref_src=twsrc%5Etfw&#34;&gt;November 26, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;some quotes from the answers I get from Matthew&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the true distribution is multinomial. The conditional distr has of each gene is Poisson. Since there are so many genes each gene is approximately independent so independent Poissons can be used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;the marginal distribution of the true multinomial is binomial, which can be approximated by Poisson.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Real data is over dispersed since the Poisson only models technical variance not biological. To model the biological variance we use a mixture of poisons with a gamma prior — the gamma prior accounting for biological variability. The marginal distr of counts is negative binomial&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I am going to use multinomial distribution for the same data I used in my last post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(tidyverse)
# There is an error when using this function, need to use the dev branch.
# https://github.com/satijalab/seurat/issues/2060
svensson_data&amp;lt;- ReadH5AD(&amp;quot;~/Downloads/svensson_chromium_control.h5ad&amp;quot;)

raw_counts&amp;lt;- svensson_data@assays$RNA@counts

# there are two datasets, each with 2000 cells
colnames(raw_counts) %&amp;gt;% stringr::str_extract(&amp;quot;[0-9]+_&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## 20311_ 20312_ 
##   2000   2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I am going to use only the second dataset sevensson et al 2
raw_counts2&amp;lt;- raw_counts[, grepl(pattern = &amp;quot;20312_&amp;quot;, x = colnames(raw_counts))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;counts from a gene fit a binomial distribution in a cell.&lt;/p&gt;
&lt;p&gt;Given
&lt;span class=&#34;math inline&#34;&gt;\(\displaystyle \Pr(X=k)={\binom {n}{k}}p^{k}(1-p)^{n-k}\)&lt;/span&gt; for binomial distribution,&lt;/p&gt;
&lt;p&gt;the marginal mean for each gene is &lt;span class=&#34;math inline&#34;&gt;\(E[y_{ij}]=n_ip_{ij} = \mu_{ij}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the marginal variance is &lt;span class=&#34;math inline&#34;&gt;\(Var[y_{ij}] = n_ip_{ij}(1-p_{ij}) = \mu_{ij}- \frac1{n_i}\mu_{ij}^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the probability of seeing a 0 count for a gene is: &lt;span class=&#34;math inline&#34;&gt;\((1-p_{ij})^{n_i} = (1-\frac{\mu_{ij}}{n_i})^{n_i}\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/const-ae/sparseMatrixStats
library(sparseMatrixStats)
library(tidyverse)
gene_means&amp;lt;- sparseMatrixStats::rowMeans2(raw_counts2)


## total counts for each cell
lib_size&amp;lt;- sparseMatrixStats::colSums2(raw_counts2)

## https://github.com/willtownes/scrna2019/blob/master/real/zheng_2017_monocytes/02_exploratory.Rmd#L290
## why median though?
n_i&amp;lt;- median(lib_size)

# probability of 0 for each gene given binomial distribution 
zeros_bn&amp;lt;- (1- gene_means/n_i)^n_i 


## this is copied from last post, probability of 0 given negative binomiral distribution
phi &amp;lt;- 1/0.3725
zeros_nb&amp;lt;- (phi/(gene_means + phi))^phi

zeros_observed&amp;lt;- apply(raw_counts2, 1, function(x) mean(x ==0))

data.frame(zeros_bn = zeros_bn, zeros_nb = zeros_nb, zeros_observed = zeros_observed, 
           gene_means = gene_means) %&amp;gt;%
  ggplot(aes(x =log10(gene_means), y = zeros_observed)) +
  geom_point() +
  geom_line(aes(x = log10(gene_means), y = zeros_nb), color = &amp;quot;red&amp;quot;) +
  geom_line(aes(x = log10(gene_means), y = zeros_bn), color = &amp;quot;blue&amp;quot;) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At least for this dataset, negative bionomial (red line) seems to fit the observed 0 count better. multinomial with marginal binomial (blue line) seems to support 0 inflated in single-cell RNAseq.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt; 12/10/2019, as Will pointed out in the comment, we need to downsample the single cell data making each cell has roughly the same number of reads. He replicated my analysis at &lt;a href=&#34;https://github.com/willtownes/scrna2019/blob/master/real/svensson_2019/01_exploratory.Rmd&#34; class=&#34;uri&#34;&gt;https://github.com/willtownes/scrna2019/blob/master/real/svensson_2019/01_exploratory.Rmd&lt;/a&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Hi thanks for your interest, in order to make those plots, you have to be able to treat all the cells/droplets as being drawn from same multinomial distribution meaning all the “n_i” terms have to be the same (or at least close). We used downsampling to achieve that…
&lt;/p&gt;
— Will (&lt;span class=&#34;citation&#34;&gt;@sandakano&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/sandakano/status/1199709577144623106?ref_src=twsrc%5Etfw&#34;&gt;November 27, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I will put them in the same blog post for completeness.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## from https://github.com/willtownes/scrna2019/blob/master/util/functions.R#L67

Down_Sample_Matrix&amp;lt;-function(expr_mat,min_lib_size=NULL){
  #adapted from https://hemberg-lab.github.io/scRNA.seq.course/cleaning-the-expression-matrix.html#normalisations
  min_sz&amp;lt;-min(colSums(expr_mat))
  if(is.null(min_lib_size)){
    min_lib_size&amp;lt;-min_sz
  } else {
    stopifnot(min_lib_size&amp;lt;=min_sz)
  }
  down_sample&amp;lt;-function(x){
    prob &amp;lt;- min_lib_size/sum(x)
    unlist(lapply(x,function(y){rbinom(1, y, prob)}))
  }
  apply(expr_mat, 2, down_sample)
}


gg&amp;lt;-sparseMatrixStats::rowSums2(raw_counts2)&amp;gt;0 #exclude genes that are zero across all cells
Y&amp;lt;-raw_counts2[gg,]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make the droplets comparable, we will exclude droplets with total count below 2,000 and downsample all other droplets to have approximately the same total counts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;total_counts&amp;lt;- sparseMatrixStats::colSums2(Y)

hist(total_counts,breaks=100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yss&amp;lt;-Y[,total_counts&amp;gt;2000]
#downsample to normalize droplet size (total UMI)
Yds&amp;lt;-Down_Sample_Matrix(as.matrix(Yss))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;using-the-downsampled-matrix-yss-for-plotting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;using the downsampled matrix Yss for plotting&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yds&amp;lt;-Yds[rowSums(Yds)&amp;gt;0,]

gene_means&amp;lt;- rowMeans(Yds)
gene_vars&amp;lt;- apply(Yds, 1, var)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;after downsampling, the mean and variance now are the same suggesting possion distribution&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- bind_cols(gene_means = gene_means, gene_vars = gene_vars)
 
df %&amp;gt;% ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = &amp;quot;red&amp;quot;) + 
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al 2 downsample&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is consistent with &lt;a href=&#34;https://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-poisson-scrna-seq-data-negative-binomial&#34;&gt;Count depth variation makes Poisson scRNA-seq data Negative Binomial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let’s see how the observed 0 counts fit each model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total counts for each cell
lib_size&amp;lt;- colSums(Yds)

## https://github.com/willtownes/scrna2019/blob/master/real/zheng_2017_monocytes/02_exploratory.Rmd#L290

N&amp;lt;-median(colSums(Yds))
predict_zeros_binom&amp;lt;-function(x){(1-exp(x)/N)^N} #binomial
predict_zeros_poi&amp;lt;-function(x){exp(-exp(x))}
predict_zeros_nb&amp;lt;-function(x,phi=100){
  exp(-phi*log1p(exp(x-log(phi))))
}

## note it is natural log here.
data.frame(zeros_observed = rowMeans(Yds==0), 
           x = log(gene_means)) %&amp;gt;%
  ggplot(aes(x , y = zeros_observed), alpha = 0.5) +
  geom_point() +
  stat_function(aes(x,color=&amp;quot;bin&amp;quot;),fun=predict_zeros_binom) +
  stat_function(aes(x,color=&amp;quot;poi&amp;quot;),fun=predict_zeros_poi) +
  stat_function(aes(x,color=&amp;quot;nb&amp;quot;),fun=predict_zeros_nb) +
  scale_color_manual(&amp;quot;model&amp;quot;,breaks=c(&amp;quot;bin&amp;quot;,&amp;quot;poi&amp;quot;,&amp;quot;nb&amp;quot;),values=c(&amp;quot;blue&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;red&amp;quot;)) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After downsampling&lt;/strong&gt;, “Poisson, binomial and negative binomial models all fit the data about the same.”&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>negative bionomial distribution in (single-cell) RNAseq </title>
      <link>/post/negative-bionomial-distribution-in-single-cell-rnaseq/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/negative-bionomial-distribution-in-single-cell-rnaseq/</guid>
      <description>&lt;p&gt;This post is inspired by two posts written by Valentine Svensson:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nxn.se/valent/2017/11/16/droplet-scrna-seq-is-not-zero-inflated&#34; class=&#34;uri&#34;&gt;http://www.nxn.se/valent/2017/11/16/droplet-scrna-seq-is-not-zero-inflated&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-Poisson-scrna-seq-data-negative-binomial&#34; class=&#34;uri&#34;&gt;http://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-Poisson-scrna-seq-data-negative-binomial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The original ipython notebook can be found at &lt;a href=&#34;https://github.com/vals/Blog/blob/master/171116-zero-inflation/Negative%20control%20analysis.ipynb&#34; class=&#34;uri&#34;&gt;https://github.com/vals/Blog/blob/master/171116-zero-inflation/Negative%20control%20analysis.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks for writing those and put both the data and code in public. After I read &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/582064v1&#34;&gt;Droplet scRNA-seq is not zero-inflated&lt;/a&gt; by Valentine Svensson, I want to gain some understanding of it. This post is an effort to replicate some of the analysis in the preprint using &lt;code&gt;R&lt;/code&gt;. The original analysis was carried out in &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I am going to use the same negative control scRNAseq data used in the paper. Negative control data are generated by adding a solution of RNA to the fluid in microfluidic systems so that each droplet contains the same RNA content.&lt;/p&gt;
&lt;p&gt;The negative control data can be downloaded from &lt;a href=&#34;https://figshare.com/projects/Zero_inflation_in_negative_control_data/61292&#34; class=&#34;uri&#34;&gt;https://figshare.com/projects/Zero_inflation_in_negative_control_data/61292&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(tidyverse)
# There is an error when using this function, need to use the dev branch.
# https://github.com/satijalab/seurat/issues/2060
svensson_data&amp;lt;- ReadH5AD(&amp;quot;~/Downloads/svensson_chromium_control.h5ad&amp;quot;)

raw_counts&amp;lt;- svensson_data@assays$RNA@counts

# there are two datasets, each with 2000 cells
colnames(raw_counts) %&amp;gt;% stringr::str_extract(&amp;quot;[0-9]+_&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## 20311_ 20312_ 
##   2000   2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I am going to use only the second dataset sevensson et al 2
raw_counts2&amp;lt;- raw_counts[, grepl(pattern = &amp;quot;20312_&amp;quot;, x = colnames(raw_counts))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s check the mean and variance relationship for all the genes&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/const-ae/sparseMatrixStats
library(sparseMatrixStats)
library(tidyverse)
gene_means&amp;lt;- sparseMatrixStats::rowMeans2(raw_counts2)
gene_vars&amp;lt;- sparseMatrixStats::rowVars(raw_counts2)

df&amp;lt;- bind_cols(gene_means = gene_means, gene_vars = gene_vars)
 
df %&amp;gt;% ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see when the gene expression level is bigger, the variance is also bigger- a quadratic relationship as opposed to possion distribution in which the mean is equal to variance.&lt;/p&gt;
&lt;p&gt;Poisson distribution is a common model for count data as well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Poisson distribution, named after French mathematician Siméon Denis Poisson, is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The probability density function is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle P(k{\text{ events in interval}})={\frac {\lambda ^{k}e^{-\lambda }}{k!}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with only one positive real &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; as the parameter.&lt;/p&gt;
&lt;p&gt;One can prove mathematically the mean is equal to the variance and equal to &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X)= Var(X) = \lambda\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Remember from my last &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/negative-binomial-distribution-in-scrnaseq/&#34;&gt;post&lt;/a&gt;, for negative binomial distribution, the Variance is in a quadratic relationship with the mean. It seems that &lt;strong&gt;for each gene&lt;/strong&gt;, the counts across all cells in scRNAseq data can be modeled with negative binomial distribution better than possion since we observed mean not equal to variance according to the scatter plot.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var = \mu + \frac {\mu^2}{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In fact, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is always postive, so we will always have &lt;span class=&#34;math inline&#34;&gt;\(Var &amp;gt; \mu\)&lt;/span&gt;. When &lt;span class=&#34;math inline&#34;&gt;\(\frac {1}{\phi} = 0\)&lt;/span&gt;, it is the possion distribution.&lt;/p&gt;
&lt;p&gt;Let’s assume each gene follows negative binomial distribution and we can fit a linear regression line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&amp;lt;- lm(gene_vars ~  1* gene_means + I(gene_means^2) + 0, data =df )
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = gene_vars ~ 1 * gene_means + I(gene_means^2) + 0, 
##     data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1457.42     0.00     0.00     0.02   802.42 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
## I(gene_means^2) 3.725e-01  6.352e-05    5863   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 11.24 on 24115 degrees of freedom
## Multiple R-squared:  0.9993, Adjusted R-squared:  0.9993 
## F-statistic: 3.438e+07 on 1 and 24115 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see the coefficient estimate is &lt;code&gt;0.3725&lt;/code&gt; for the &lt;span class=&#34;math inline&#34;&gt;\(\mu^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac 1\phi = 0.3725\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the same value as calculated in the preprint by Valentine Svensson:
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/582064v1&#34;&gt;Droplet scRNA-seq is not zero-inflated&lt;/a&gt; table 1.&lt;/p&gt;
&lt;p&gt;Let’s plot the fitted line to the mean variance plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predicted_df&amp;lt;- data.frame(mean = df$gene_means, var_predict = 
                            df$gene_means + 0.3725 * (df$gene_means)^2 )

df %&amp;gt;%  ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        geom_line(color = &amp;quot;red&amp;quot;, data = predicted_df, aes(x = log10(gene_means), y =log10(var_predict))) + 
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Given the &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and mean of a gene, we can calculate the probability of observing 0 count for that gene:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Pr(X=0) = \left(\frac{\phi} {\mu + \phi}\right)^{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;is-single-cell-rnaseq-data-0-inflated&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Is single cell RNAseq data 0 inflated?&lt;/h3&gt;
&lt;p&gt;Now, let’s plot the observed 0s vs the theoretical 0s given the data fit negative binomial distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phi &amp;lt;- 1/0.3725

zeros_nb&amp;lt;- (phi/(gene_means + phi))^phi
zeros_observed&amp;lt;- apply(raw_counts2, 1, function(x) mean(x ==0))

data.frame(zeros_nb = zeros_nb, zeros_observed = zeros_observed, 
           gene_means = gene_means) %&amp;gt;%
  ggplot(aes(x =log10(gene_means), y = zeros_observed)) +
  geom_point() +
  geom_line(aes(x = log10(gene_means), y = zeros_nb), color = &amp;quot;red&amp;quot;) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see it fits very well. That’s why Valentine says this scRNAseq data is &lt;strong&gt;NOT&lt;/strong&gt; 0 inflated.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>negative binomial distribution</title>
      <link>/post/negative-binomial-distribution-in-scrnaseq/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/negative-binomial-distribution-in-scrnaseq/</guid>
      <description>&lt;p&gt;“Every model is wrong, but some are useful”— George Box&lt;/p&gt;
&lt;p&gt;In an effort to better understand the distribution of single-cell RNAseq counts,
I dived a bit deeper into the negative binomial distribution in the context of &lt;code&gt;R&lt;/code&gt;. I am by no means an
expert in statistics and writing this post is for myself to better understand it.&lt;/p&gt;
&lt;div id=&#34;what-is-a-negative-binomial-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;what is a negative binomial distribution&lt;/h3&gt;
&lt;p&gt;I will quote from &lt;a href=&#34;https://en.wikipedia.org/wiki/Negative_binomial_distribution&#34;&gt;wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose there is a sequence of independent Bernoulli trials. Thus, each trial has two potential outcomes called “success” and “failure”. In each trial the probability of success is p and of failure is (1 − p). We are observing this sequence until a predefined number r of failures have occurred. Then the random number of successes we have seen, X, will have the negative binomial (or Pascal) distribution:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X\sim \mathrm {NB} (r,\,p)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The probability mass function of the negative binomial distribution is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(k;r,p)\equiv \Pr(X=k)={\binom {k+r-1}{k}}(1-p)^{r}p^{k}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Sometimes the distribution is parameterized in terms of its mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; :&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle {\begin{aligned}&amp;amp;p={\frac {\sigma ^{2}-\mu }{\sigma ^{2}}},\\[6pt]&amp;amp;r={\frac {\mu ^{2}}{\sigma ^{2}-\mu }},\\[3pt]&amp;amp;\Pr(X=k)={k+{\frac {\mu ^{2}}{\sigma ^{2}-\mu }}-1 \choose k}\left({\frac {\sigma ^{2}-\mu }{\sigma ^{2}}}\right)^{k}\left({\frac {\mu }{\sigma ^{2}}}\right)^{\mu ^{2}/(\sigma ^{2}-\mu )}.\end{aligned}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s see how it is implemented in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;Open the help page &lt;code&gt;?rnbinom&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rnbinom(n, size, prob, mu)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(x;n,p)\equiv \Pr(X=x)={\binom {n+x-1}{n-1}}(1-p)^{x}p^{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This represents the number of failures which occur in a sequence of Bernoulli trials before a target number of successes (n) is reached.&lt;/strong&gt; The mean is μ = n(1-p)/p and variance n(1-p)/p^2.&lt;/p&gt;
&lt;p&gt;Notice the difference from the definition from wiki above.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;size&lt;br /&gt;
target for number of successful trials, or dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the n in the formula.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;prob&lt;br /&gt;
probability of success in each trial. 0 &amp;lt; prob &amp;lt;= 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the p in the formula.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mu
alternative parametrization via mean: see ‘Details’.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Details:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An alternative parametrization (often used in ecology) is by the mean mu (see above), and size, the dispersion parameter, where prob = size/(size+mu). The variance is mu + mu^2/size in this parametrization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is a bit confusing since we can define it in different ways. We can verify it by ourselves.&lt;/p&gt;
&lt;p&gt;Suppose we do independent Bernoulli trails 10 times, with a success probability of 0.4, what’s the probability we see 4 failures before the 6th success?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## this is the total number of failures, the random variable X 
x&amp;lt;- 4

p&amp;lt;- 0.4

## size, the number of successful trials we are targeting
size &amp;lt;- 10 - x

dnbinom(x= x, size = size, prob = p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;one possible outcome is:&lt;/p&gt;
&lt;p&gt;SSSSSFFFFS&lt;/p&gt;
&lt;p&gt;The last trail has to be a success.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## this is the same as 
choose(size + x -1, size-1) * p^(size) * (1-p)^x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## and 
choose(size + x -1, x) * p^(size) * (1-p)^x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we can simulate the negative binomial distribution counts by&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

rnbinom(10000, size = size, prob =p) %&amp;gt;%
        enframe(name = &amp;quot;seq&amp;quot;, value = &amp;quot;num&amp;quot;) %&amp;gt;%
        ggplot(aes(x = num)) +
        geom_histogram(col=&amp;quot;white&amp;quot;, bins = 30) +
        geom_vline(xintercept = x, linetype = 2, col= &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-13-negative-binomial-distribution-in-scrnaseq_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(rnbinom(10000, size = size, prob =p) == x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0664&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see it is close to the exact probability.&lt;/p&gt;
&lt;p&gt;An alternative parametrization (often used in ecology) is by the mean mu (see above), and size, the dispersion parameter, where prob = size/(size+mu). The variance is mu + mu^2/size in this parametrization.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X\sim \mathrm {NB} (\mu,\,\sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu&amp;lt;- size/p - size 
mu&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variance&amp;lt;- mu + mu^2/size 
variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dnbinom(x= x, size = size, mu = mu)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see it is the same result.&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(x;n,p)\equiv \Pr(X=x)={\binom {n+x-1}{n-1}}(1-p)^{x}p^{n}}\]&lt;/span&gt;
we can calculate the probablity when x = 0
i.e. the probability that we see a 0 count in RNAseq data.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle\Pr(X=0)=p^{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and we know prob = size/(size+mu)&lt;/p&gt;
&lt;p&gt;The size or &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is dispersion parameter in gamma distribution (the shape parameter of the gamma mixing distribution). let’s replace the p using &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Pr(X=0) = \left(\frac{\phi} {\mu + \phi}\right)^{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The variance is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var = \mu + \frac {\mu^2}{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My opinionated selection of books/urls for bioinformatics/data science curriculum</title>
      <link>/post/my-opinionated-selection-of-books-for-bioinformatics-data-science-curriculum/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/my-opinionated-selection-of-books-for-bioinformatics-data-science-curriculum/</guid>
      <description>

&lt;p&gt;There was a paper on this topic: &lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003662&#34; target=&#34;_blank&#34;&gt;A New Online Computational Biology Curriculum&lt;/a&gt;.&lt;br /&gt;
I am going to provide a biased list below (I have read most of the books if not all). I say it is biased because you will see many books of R are from Hadely Wickham. I now use &lt;a href=&#34;https://www.tidyverse.org/&#34; target=&#34;_blank&#34;&gt;tidyverse&lt;/a&gt; most of the time.&lt;/p&gt;

&lt;h2 id=&#34;unix&#34;&gt;Unix&lt;/h2&gt;

&lt;p&gt;I suggest people who want to learn bioinformatics starting to learn unix commands first. It is so powerful and also omnipresent in high-performance computing settings (clouding computing etc). You can not survive without knowing it.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://linuxcommand.org/tlcl.php&#34; target=&#34;_blank&#34;&gt;The linux command line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nostarch.com/howlinuxworks2&#34; target=&#34;_blank&#34;&gt;How Linux works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datascienceatthecommandline.com/&#34; target=&#34;_blank&#34;&gt;Data science at the command line&lt;/a&gt;
It was a fun reading for me and learned many tricks from this book.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rik.smith-unna.com/command_line_bootcamp&#34; target=&#34;_blank&#34;&gt;command line bootcamp&lt;/a&gt; interactive online session to learn unix. it is not working anymore unfortunately.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;computational-biology&#34;&gt;Computational biology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://library.open.oregonstate.edu/computationalbiology/&#34; target=&#34;_blank&#34;&gt;A Primer for Computational Biology&lt;/a&gt; by Shawn T. O&amp;rsquo;Neil&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://practicalcomputing.org/&#34; target=&#34;_blank&#34;&gt;Practical computing for biologist&lt;/a&gt; by  Steven H.D Haddock and Casey W. Dunn This was the first book that I used to learn unix, regex and python.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920030157.do&#34; target=&#34;_blank&#34;&gt;Bioinformatics data skills&lt;/a&gt; by Vince Buffalo. This is a must have! once you have some experience on bioinformatics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;r-programming&#34;&gt;R programming&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r4ds.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R for data science&lt;/a&gt; by Garrett Grolemund and Hadley Wickham.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://adv-r.had.co.nz/&#34; target=&#34;_blank&#34;&gt;Advanced R&lt;/a&gt; by Hadley Wickham.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://r-pkgs.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R packages&lt;/a&gt; by Hadley Wickham. If you want to transit from an R user to developer, writing an R package will get you started.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;stats-r-focused&#34;&gt;Stats  (R focused)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rafalab.github.io/pages/harvardx.html&#34; target=&#34;_blank&#34;&gt;Data analysis for the life science with R&lt;/a&gt; by Micheal Love and Rafael A. Irizarry. I took the course on edx for 3 times! learned a ton! You can buy a paper book at &lt;a href=&#34;https://www.crcpress.com/Data-Analysis-for-the-Life-Sciences-with-R/Irizarry-Love/p/book/9781498775670&#34; target=&#34;_blank&#34;&gt;https://www.crcpress.com/Data-Analysis-for-the-Life-Sciences-with-R/Irizarry-Love/p/book/9781498775670&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://compgenomr.github.io/book/&#34; target=&#34;_blank&#34;&gt;Computational Genomics with R&lt;/a&gt; by Altuna Akalin.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/bios221/book/&#34; target=&#34;_blank&#34;&gt;Mordern statistics for mordern biology&lt;/a&gt; by Susan Holmes and Wolfgang Huber.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;python-programming&#34;&gt;Python programming&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pythonforbiologists.com/advanced-python-for-biologists&#34; target=&#34;_blank&#34;&gt;(Advanced) python for biologist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wesmckinney.com/pages/book.html&#34; target=&#34;_blank&#34;&gt;Python for data analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/data-science-from/9781492041122/&#34; target=&#34;_blank&#34;&gt;Data science from scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;machine-learning&#34;&gt;Machine learning&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/ISL/&#34; target=&#34;_blank&#34;&gt;An intro to statistical learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/practical-data-science-with-r&#34; target=&#34;_blank&#34;&gt;Practical Data science with R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34; target=&#34;_blank&#34;&gt;Deeping learning with R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;visualization&#34;&gt;Visualization&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://serialmentor.com/dataviz/&#34; target=&#34;_blank&#34;&gt;Fundamentals of Data Visualization&lt;/a&gt; by Claus O.Wilke&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Visual-Display-Quantitative-Information/dp/1930824130&#34; target=&#34;_blank&#34;&gt;The Visual Display of Quantitative Information&lt;/a&gt; by Edward R. Tufte as well.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Those two books are not teaching you how to make figures programmatically (although the book by Claus was generated by Rmarkdown and the codes for all the figures can be found at &lt;a href=&#34;https://github.com/clauswilke/dataviz&#34; target=&#34;_blank&#34;&gt;https://github.com/clauswilke/dataviz&lt;/a&gt;). They teach you what kind of figures are informative and pleasant to eyes. &lt;a href=&#34;https://www.data-to-viz.com/&#34; target=&#34;_blank&#34;&gt;From data to viz&lt;/a&gt; is a website guiding you to choose the right graph for your data.&lt;/p&gt;

&lt;p&gt;I am still using R/ggplot2 for visualization.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://socviz.co/&#34; target=&#34;_blank&#34;&gt;Data Visualization&lt;/a&gt; by Kieran Healy.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cookbook-r.com/Graphs/&#34; target=&#34;_blank&#34;&gt;R Graphics Cookbook&lt;/a&gt; by Winston Chang.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/0387981403&#34; target=&#34;_blank&#34;&gt;ggplot2: Elegant Graphics for Data Analysis&lt;/a&gt; by Hadely Wickham.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally, I have compiled many useful links at &lt;a href=&#34;https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s your favorite book that I have missed? Comment below!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/books.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harvard FAS informatics nanocourse</title>
      <link>/talk/2019-harvard-fas-workshop/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 -0400</pubDate>
      
      <guid>/talk/2019-harvard-fas-workshop/</guid>
      <description>&lt;p&gt;In this 2-week long Harvard FAS informatics nanocourse, I co-taught snakemake
for one afternoon and lead-instructed scRNAseq analysis for a full day.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The snakemake workshop material was adapted from Titus Brown and can be found at
&lt;a href=&#34;https://github.com/crazyhottommy/2019-snakemake-Harvard-Informatics-nanocourse&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/2019-snakemake-Harvard-Informatics-nanocourse&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The scRNAseq workshop material was developed using &lt;a href=&#34;https://github.com/jdblischak/workflowr&#34; target=&#34;_blank&#34;&gt;workflowr&lt;/a&gt; and can be found at
&lt;a href=&#34;https://crazyhottommy.github.io/scRNA-seq-workshop-Fall-2019/&#34; target=&#34;_blank&#34;&gt;https://crazyhottommy.github.io/scRNA-seq-workshop-Fall-2019/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The rest of the nanocourse material can be found at &lt;a href=&#34;https://github.com/harvardinformatics/micro-course&#34; target=&#34;_blank&#34;&gt;https://github.com/harvardinformatics/micro-course&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I used the &lt;a href=&#34;https://carpentries.org/&#34; target=&#34;_blank&#34;&gt;carpentries&lt;/a&gt; teaching style. A blue sticky note means OK and a red sticky note means having problems.&lt;/p&gt;

&lt;p&gt;Snakemake in action!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/snakemake_wp.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;scRNAseq workshop in a lamont library.
&lt;img src=&#34;/img/scRNAseq_wp.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Develop Bioconductor packages with docker container</title>
      <link>/post/develop-bioconductor-packages-with-docker-container/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/develop-bioconductor-packages-with-docker-container/</guid>
      <description>

&lt;h3 id=&#34;readings&#34;&gt;Readings&lt;/h3&gt;

&lt;p&gt;links to read:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.bioconductor.org/developers/package-guidelines/#rcode&#34; target=&#34;_blank&#34;&gt;https://www.bioconductor.org/developers/package-guidelines/#rcode&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/Bioconductor/Contributions&#34; target=&#34;_blank&#34;&gt;https://github.com/Bioconductor/Contributions&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;use container  &lt;a href=&#34;https://github.com/Bioconductor/bioconductor_full&#34; target=&#34;_blank&#34;&gt;https://github.com/Bioconductor/bioconductor_full&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am following the last link.&lt;/p&gt;

&lt;h3 id=&#34;pull-the-container&#34;&gt;pull the container&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull bioconductor/bioconductor_full:devel
docker images 

REPOSITORY                       TAG                  IMAGE ID            CREATED             SIZE
bioconductor/bioconductor_full   devel                ae3ec2be7376        3 hours ago         5.7GB
seuratv3                         latest               9b358ab1fd63        2 days ago          2.76GB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is 5.7G in size.&lt;/p&gt;

&lt;p&gt;start the Rstuido from the image. I have another Rstudio instance using port 8787, let me use a different one (e.g. 8080).  docker Rstudio default port is &lt;code&gt;8787&lt;/code&gt;, change the host port to &lt;code&gt;8080&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/R/host-site-library

docker run                                      \
  -e PASSWORD=&amp;quot;xyz&amp;quot;                   \
  -p 8080:8787                                \
  -v ~/R/host-site-library:/usr/local/lib/R/host-site-library  \
  -v ~/github_repos:/home/rstudio \
  bioconductor/bioconductor_full:devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NOTE: The path &lt;code&gt;~/R/host-site-library&lt;/code&gt; is mapped to .libPaths() in R. So, when R is started, all the libraries in the host directory &lt;code&gt;host-site-library&lt;/code&gt; are available to R. It is stored on your machine mounted from the volume you fill in place of host-site-library.&lt;/p&gt;

&lt;p&gt;The mounted path must be an &lt;strong&gt;absolute path&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I also mounted the &lt;code&gt;github_repo&lt;/code&gt; folder in my host machine to the docker home directory. Because every time you exit a container and start it again, the modification you did to the container will be gone (unless you make an modified image and use that for the next time). I will save the R package in my &lt;code&gt;~/github_repo&lt;/code&gt; folder in the host machine.&lt;/p&gt;

&lt;p&gt;type &lt;code&gt;localhost:8080&lt;/code&gt;, you should see the Rstudio login page. username is &lt;code&gt;rstudio&lt;/code&gt;, password is &lt;code&gt;xyz&lt;/code&gt; in this dummy example.&lt;/p&gt;

&lt;p&gt;In Rstudio:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; .libPaths()
[1] &amp;quot;/usr/local/lib/R/host-site-library&amp;quot; &amp;quot;/usr/local/lib/R/site-library&amp;quot;     
[3] &amp;quot;/usr/local/lib/R/library&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you will see &lt;code&gt;/usr/local/lib/R/host-site-library&lt;/code&gt; is in the &lt;code&gt;libpath&lt;/code&gt;, that corresponds to the &lt;code&gt;~/R/host-site-library&lt;/code&gt; in the host machine, if you do package installation, it will be installed in the&lt;code&gt;~/R/host-site-library&lt;/code&gt; .&lt;/p&gt;

&lt;h3 id=&#34;start-an-r-package-use-usethis&#34;&gt;start an R package use usethis&lt;/h3&gt;

&lt;p&gt;follow these two blog posts and &lt;a href=&#34;http://r-pkgs.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R packages book&lt;/a&gt; by Hadley Wickham:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blog.methodsconsultants.com/posts/developing-r-packages-using-gitlab-ci-part-i/&#34; target=&#34;_blank&#34;&gt;https://blog.methodsconsultants.com/posts/developing-r-packages-using-gitlab-ci-part-i/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.hvitfeldt.me/blog/usethis-workflow-for-package-development/&#34; target=&#34;_blank&#34;&gt;https://www.hvitfeldt.me/blog/usethis-workflow-for-package-development/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(c(&amp;quot;devtools&amp;quot;, &amp;quot;roxygen2&amp;quot;, &amp;quot;usethis&amp;quot;, &amp;quot;available&amp;quot;, &amp;quot;rmarkdown&amp;quot;))

## check if the package name is avaiable (not used by others)
library(available)
available(&amp;quot;myawesomepackage&amp;quot;)

library(usethis)
usethis::create_package(&amp;quot;~/myawesomepackage&amp;quot;)

use_git()
use_github()
use_mit_license(&amp;quot;Ming Tang&amp;quot;)
usethis::use_pipe()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add a function&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;usethis::use_r(&amp;quot;myawesomefunc&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On mac:&lt;br /&gt;
&lt;code&gt;command + option + shift + R&lt;/code&gt; for inserting roxygen comment.&lt;br /&gt;
&lt;code&gt;command + shift + D&lt;/code&gt; for documentation.&lt;br /&gt;
&lt;code&gt;command + shfit + B&lt;/code&gt; for building package.&lt;/p&gt;

&lt;p&gt;add more functions, repeat.&lt;/p&gt;

&lt;h3 id=&#34;next&#34;&gt;Next&lt;/h3&gt;

&lt;p&gt;Next is to add test and setup some continuous integration. Read this &lt;a href=&#34;https://jef.works/blog/2019/02/17/automate-testing-of-your-R-package/&#34; target=&#34;_blank&#34;&gt;Automate testing of your R package using Travis CI, Codecov, and testthat&lt;/a&gt; by Jean Fan.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snakemake pipeline post-processing scATAC-seq</title>
      <link>/project/single-cell-atacseq/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 -0400</pubDate>
      
      <guid>/project/single-cell-atacseq/</guid>
      <description>

&lt;h3 id=&#34;what-does-it-do&#34;&gt;What does it do?&lt;/h3&gt;

&lt;p&gt;For single cell ATACseq experiment, one gets a merged bam file for all cells. After going through clustering, one groups similar cells into cell types (cell states). This workflow will split the bam by clusters to create a pseudo bulk bam for each cluster, create bigwig tracks for visulization, call peaks for each cluster and merge the peaks across the clusters. Finally it will count reads per peak per cell from the original bam file on the merged peaks.&lt;/p&gt;

&lt;p&gt;In the future, the peak calling software should be barcode aware, so one does not need to split the bam file by cluster. But for now, I have this work for me.&lt;/p&gt;

&lt;p&gt;You can find the workflow at my &lt;a href=&#34;https://github.com/crazyhottommy/pyflow-scATACseq&#34; target=&#34;_blank&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/rulegraph_scATAC.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Run Rstudio server with singularity on HPC</title>
      <link>/post/run-rstudio-server-with-singularity-on-hpc/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/run-rstudio-server-with-singularity-on-hpc/</guid>
      <description>

&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;

&lt;p&gt;Please read the following before go ahead:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;docker&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.rocker-project.org/&#34; target=&#34;_blank&#34;&gt;Rocker&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.sylabs.io/docs/&#34; target=&#34;_blank&#34;&gt;singularity&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;from Harvard Research computing website: &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/&#34; target=&#34;_blank&#34;&gt;Odyssey has singularity installed&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Why Singularity?
There are some important differences between Docker and Singularity:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Docker and Singularity have their own container formats.&lt;/li&gt;
&lt;li&gt;Docker containers may be imported to run via Singularity.&lt;/li&gt;
&lt;li&gt;Docker containers need root privileges for full functionality which is not suitable for a shared HPC environment.&lt;/li&gt;
&lt;li&gt;Singularity allows working with containers as a regular user. No sudo is required,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our &lt;a href=&#34;https://informatics.fas.harvard.edu/&#34; target=&#34;_blank&#34;&gt;informatics group&lt;/a&gt; has several big memory (1TB) computing nodes that allow us to run interactive jobs. I want to have big memory to run Rstudio for my scRNAseq data.&lt;/p&gt;

&lt;h3 id=&#34;run-rstudio-server-with-singularity&#34;&gt;Run Rstudio server with singularity&lt;/h3&gt;

&lt;p&gt;I basically followed this tutorial &lt;a href=&#34;https://www.rocker-project.org/use/singularity/&#34; target=&#34;_blank&#34;&gt;https://www.rocker-project.org/use/singularity/&lt;/a&gt; written by my colleague Nathan Weeks sitting in the same office with me. Thanks!&lt;/p&gt;

&lt;p&gt;First, go to &lt;a href=&#34;https://www.rocker-project.org/images/&#34; target=&#34;_blank&#34;&gt;https://www.rocker-project.org/images/&lt;/a&gt; choose the image you want. I use &lt;code&gt;tidyverse&lt;/code&gt; heavily, so I downloaded the &lt;code&gt;tidyverse&lt;/code&gt; image buit upon &lt;code&gt;Rstudio&lt;/code&gt; image&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## ssh to remote HPC and pull the docker image by singularity
ssh bio1
mkdir singularity-images; cd !$
singularity pull --name rstudio.simg docker://rocker/tidyverse:latest


# This example bind mounts the /project directory on the host into the Singularity container.
# By default the only host file systems mounted within the container are $HOME, /tmp, /proc, /sys, and /dev.
# type in the password you want to set, make it more complicated than this dummy one
PASSWORD=&#39;xyz&#39; singularity exec --bind=/project  rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;back to my mac and connect to it via &lt;a href=&#34;https://www.ssh.com/ssh/tunneling/&#34; target=&#34;_blank&#34;&gt;SSH tunnel&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Nathan explained by drawing the following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/ssh_tunnel.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh -Nf -L 8787:localhost:8787 bio1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on my local mac, open &lt;code&gt;localhost:8787&lt;/code&gt; in web browser, type in the Odyssey (HPC) user name and password (xyz in this dummy example). Rstudio server now is ready for me! Magic!!!&lt;/p&gt;

&lt;p&gt;Note: if mulitple people using the same node for Rstudio sever, you will need to pick a different
port than &lt;code&gt;8787&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;one-more-note-on-r-packages&#34;&gt;One more note on R packages&lt;/h3&gt;

&lt;p&gt;create an &lt;code&gt;.Renviron&lt;/code&gt; file in your home diretory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# User-installed R packages go into their home directory
echo &#39;R_LIBS_USER=~/R/%p-library/%v&#39; &amp;gt;&amp;gt; ${HOME}/.Renviron
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The platform and version will be replaced by the corresponding R versions&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls ~/R/x86_64-pc-linux-gnu-library/
3.6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;install packages inside Rstudio and the packages will be installed to &lt;code&gt;~/R/x86_64-pc-linux-gnu-library/3.6&lt;/code&gt;. R version in this singularity image is R3.6. Note that if you use R on command line at the remote machine and use the same version of R. the library may not be compatible. e.g. singularity container is based on debian （Ubuntu) and HPC is based on RPM (CentOS). One may need to have mulitiple &lt;code&gt;.Renviron&lt;/code&gt; file and switch back and forth depending on which R one is using. If you have better options, please let me know!&lt;/p&gt;

&lt;h3 id=&#34;jump-to-other-folders&#34;&gt;Jump to other folders&lt;/h3&gt;

&lt;p&gt;by default, Rstudio opens the home directory. if you want to go to other folders, you can click &lt;code&gt;...&lt;/code&gt; in the file pane.
You can then type in the path you want to jump to.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/change_path.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;submit-a-slurm-job&#34;&gt;Submit a slurm job&lt;/h3&gt;

&lt;p&gt;If you do not have a big computing node that you can run interactive job, you can follow Nathan&amp;rsquo;s &lt;a href=&#34;https://www.rocker-project.org/use/singularity/&#34; target=&#34;_blank&#34;&gt;tutorial&lt;/a&gt; on how to submit slurm job to run Rstudio server with singularity.&lt;/p&gt;

&lt;h3 id=&#34;fix-home-directory-filled-up-issue&#34;&gt;Fix home directory filled up issue&lt;/h3&gt;

&lt;p&gt;I am enjoying Rstudio with my HPC large computing nodes and suddenly I got emails from the HPC staff saying I am using up my home directory space. It turns out Rstudio writes the suspended session files to &lt;code&gt;~/.rstudio/&lt;/code&gt; folder. I &lt;code&gt;ncdu&lt;/code&gt; the folder and it is 34G! I googled around and found exactly this &lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/218417097-Filling-up-the-home-directory-with-RStudio-Server&#34; target=&#34;_blank&#34;&gt;Filling up the home directory with RStudio Server&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the solution is to turn off session time out.&lt;/p&gt;

&lt;p&gt;put  &lt;code&gt;session-timeout-minutes=0&lt;/code&gt; in the &lt;code&gt;/etc/rstudio/rsession.conf&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Let me take a look at the file inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;singularity shell rstudio.simg

cat /etc/rstudio/rsession.conf
# R Session Configuration File

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is an empty file. I will make a
rsession.conf file in the home directory of the host machine
adding that one line.&lt;/p&gt;

&lt;p&gt;Now, bind the modified rsession.conf file in host to the ression.conf file
inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat ~/resession.conf
# R Session Configuration File
session-timeout-minutes=0

## make a tmp folder and need to mount to /tmp inside the container for rstudio to write 
mkdir /scratch/mtang/tmp

# now open rstudio server
PASSWORD=&#39;xyz&#39; singularity exec --bind=~/rsession.conf:/etc/rstudio/rsession.conf --bind /scratch/mtang/tmp:/tmp  rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should fix the problem :)&lt;/p&gt;

&lt;p&gt;Nathan dived into the source code of Rsutido server &lt;a href=&#34;https://github.com/rstudio/rstudio/blob/master/src/cpp/server/ServerSessionManager.cpp#L111&#34; target=&#34;_blank&#34;&gt;https://github.com/rstudio/rstudio/blob/master/src/cpp/server/ServerSessionManager.cpp#L111&lt;/a&gt;
and documentation &lt;a href=&#34;https://docs.rstudio.com/ide/server-pro/r-sessions.html#user-and-group-profiles&#34; target=&#34;_blank&#34;&gt;https://docs.rstudio.com/ide/server-pro/r-sessions.html#user-and-group-profiles&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The enironment name of time out is &lt;code&gt;RSTUDIO_SESSION_TIMEOUT&lt;/code&gt;, so one can do&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PASSWORD=&#39;xyz&#39; RSTUDIO_SESSION_TIMEOUT=&#39;0&#39; singularity exec rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to have the same effect of setting up the &lt;code&gt;rsession.conf&lt;/code&gt; file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculate scATACseq TSS enrichment score</title>
      <link>/post/calculate-scatacseq-tss-enrichment-score/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/calculate-scatacseq-tss-enrichment-score/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/data-standards/terms/#enrichment&#34; target=&#34;_blank&#34;&gt;TSS enrichment score&lt;/a&gt; serves as an important quality control metric for ATACseq data. I want to write a script for single cell ATACseq data.&lt;/p&gt;

&lt;p&gt;From the Encode page:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Transcription Start Site (TSS) Enrichment Score - The TSS enrichment calculation is a signal to noise calculation. The reads around a reference set of TSSs are collected to form an aggregate distribution of reads centered on the TSSs and extending to 1000 bp in either direction (for a total of 2000bp). This distribution is then normalized by taking the average read depth in the 100 bps at each of the end flanks of the distribution (for a total of 200bp of averaged data) and calculating a fold change at each position over that average read depth. This means that the flanks should start at 1, and if there is high read signal at transcription start sites (highly open regions of the genome) there should be an increase in signal up to a peak in the middle. We take the signal value at the center of the distribution after this normalization as our TSS enrichment metric. Used to evaluate ATAC-seq.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It was not so clear to me from the definition on how &lt;strong&gt;EXACTLY&lt;/strong&gt; this score is calculated.&lt;/p&gt;

&lt;p&gt;I inspected the &lt;a href=&#34;https://github.com/jianhong/ATACseqQC/blob/master/R/TSSEscore.R#L80&#34; target=&#34;_blank&#34;&gt;source code&lt;/a&gt; of  &lt;code&gt;ATACseqQC&lt;/code&gt; which calculates the TSS enrichment score for bulk ATACseq data, but I think it is not calculating it the right way as described by the ENCODE page.&lt;/p&gt;

&lt;p&gt;I reached out to &lt;a href=&#34;https://twitter.com/Satpathology&#34; target=&#34;_blank&#34;&gt;Ansu Satpathy&lt;/a&gt; (thanks!), and got a script written by Jeffrey Granja, who are the authors of this recent scATACseq paper:
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/610550v1&#34; target=&#34;_blank&#34;&gt;Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion (2019)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I studied the script and also got the confirmation from ENCODE how they calculate the TSS enrichment score
&lt;a href=&#34;https://github.com/ENCODE-DCC/atac-seq-pipeline/issues/50&#34; target=&#34;_blank&#34;&gt;https://github.com/ENCODE-DCC/atac-seq-pipeline/issues/50&lt;/a&gt; by a python script.&lt;/p&gt;

&lt;p&gt;To work with this coverage type of data in R, I want to take advantage of the data structure &lt;code&gt;View&lt;/code&gt; in bioconductor, so I borrowed some codes from &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/genomation/inst/doc/GenomationManual.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;genomation::ScoreMatrix&lt;/code&gt;&lt;/a&gt; instead of using the script sent by Ansu. It is a very nice package by &lt;a href=&#34;https://twitter.com/AltunaAkalin&#34; target=&#34;_blank&#34;&gt;Altuna Akalin&lt;/a&gt;. A side note, he has a very nice book you might be interested in: &lt;a href=&#34;http://compgenomr.github.io/book/how-to-contribute.html&#34; target=&#34;_blank&#34;&gt;Computational Genomics with R&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Below, I ended up with a hybrid script from multiple sources.
Now it works with the 10x cellranger-atac output &lt;code&gt;fragment.tsv.gz&lt;/code&gt;. One can tweak it to work with the bam file. However, the bam file is 25G, R takes a long time to parse it.&lt;/p&gt;

&lt;p&gt;I explain what the script does:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;for each TSS, get per base coverage for the 1000 bp flanking region(flank = 1000).&lt;/li&gt;
&lt;li&gt;do this for all TSSs, We get a matrix of #TSS x 2000 bp dimension.&lt;/li&gt;
&lt;li&gt;do a column sum of the matrix.&lt;/li&gt;
&lt;li&gt;sum of the coverage of the endFlank (100bp) at both ends and divide by 200 bp to get a
normalization factor.&lt;/li&gt;
&lt;li&gt;divide the the normalization factor for -1900 to + 1900 bp to get per base normalized coverage.&lt;/li&gt;
&lt;li&gt;do a smoothing with a defined window (50bp by default) using &lt;code&gt;zoo::rollmean&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;select the highest value within a window (highest_tss_flank, 50 bp by default) around the TSS because the highest peak is not necessary at exactly the TSS site (position 0)&lt;/li&gt;
&lt;li&gt;repeat 1-7 for all cells.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;extra-technical-notes&#34;&gt;Extra technical notes:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One thing to note is that one needs to filter out the TSSs which are not within the coverage. e.g. A TSS with 1000 bp flanking regions fall out of the coverage.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;use only the common chromosomes between coverage and the txs.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;convert GRanges to IntergerRangesList does not maintain the order of the GRanges.
so a unique id was given for each Ranges, and the matrix can be reordered according to this unique id. That&amp;rsquo;s what &lt;code&gt;constrainRanges()&lt;/code&gt; does. read this thread for more &lt;a href=&#34;https://stat.ethz.ch/pipermail/bioc-devel/2016-June/009433.html&#34; target=&#34;_blank&#34;&gt;https://stat.ethz.ch/pipermail/bioc-devel/2016-June/009433.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-long-it-takes&#34;&gt;How long it takes.&lt;/h3&gt;

&lt;p&gt;It took me around ~15 seconds to calculate the TSS enrichment score for a single cell.
1.213291 hours for 5000 PBMC cells using 15 workers (not too bad :).&lt;/p&gt;

&lt;h3 id=&#34;r-code&#34;&gt;R code&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(GenomicRanges)
library(dplyr)

#&#39; checkClass function
#&#39; 
#&#39; check whether the x object corresponds to the given class
#&#39;
#&#39; @param x object
#&#39; @param class.name class name
#&#39; @param var.name uses x object
#&#39; @keywords internal
checkClass = function(x, class.name, var.name = deparse(substitute(x))){
  
  fun.name = match.call(call=sys.call(sys.parent(n=1)))[[1]]
  if(!class(x) %in% class.name)
    stop(paste(fun.name,&#39;: &#39;, 
               var.name, 
               &#39; is not of class: &#39;, 
               paste(class.name, collapse=&#39; &#39;), 
               &#39;\n&#39;, sep=&#39;&#39;))
}

### remove the tss that do not have coverage
### I took some code from the ScoreMatrix.R function in the genomation package.
### give the credit due :)
### see https://github.com/BIMSBbioinfo/genomation/blob/master/R/scoreMatrix.R#L113
constrainRanges = function(target, windows){
  
  checkClass(target, c(&#39;SimpleRleList&#39;,&#39;RleList&#39;,&#39;CompressedRleList&#39;))
  checkClass(windows, &#39;GRanges&#39;)
  
  mcols(windows)$X_rank = 1:length(windows)
  r.chr.len = elementNROWS(target)
  constraint = GRanges(seqnames=names(r.chr.len),
                       IRanges(start=rep(1,length(r.chr.len)),
                               end=as.numeric(r.chr.len)))
  # suppressWarnings is done becuause GenomicRanges function give warnings 
  #if you don&#39;t have the same seqnames in both objects
  win.list.chr = suppressWarnings(subsetByOverlaps(windows, 
                                                   constraint,
                                                   type = &amp;quot;within&amp;quot;,
                                                   ignore.strand = TRUE))
  
  if(length(win.list.chr) == 0)
    stop(&#39;All windows fell have coordinates outside windows boundaries&#39;)
  return(win.list.chr)
}



#&#39; Calculate tss enrichment score from 10xscATAC fragment file
#&#39;
#&#39; @param frag_gz_file  fragment.tsv.gz file from 10x cellranger-atac output or 
#&#39; anyother tool but in the same format.
#&#39; @param txs  a txdb object
#&#39; @param flank flanking bp of tss (upstream and downstream)
#&#39; @param endFlank  bp end flanks of flank for local noise control
#&#39;     flank               flank
#&#39;  ---------------|-----------------
#&#39;                tss
#&#39;  ---                           ---
#&#39;  endFlank                     endFlank
#&#39;  
#&#39; @param highest_tss_flank bp flanking tss windown for choosing the highest tss score.
#&#39; The highest tss enrichment score is not always exactly at tss.
#&#39; @param barcodeList valid barcode list, a file with one column 
#&#39; @param smooth window size to smooth 
#&#39; @param strand.aware consider tss strandness when calculating 
#&#39;
#&#39; @return
#&#39; @export
#&#39;
#&#39; @examples
#&#39; library(TxDb.Hsapiens.UCSC.hg19.knownGene)
#&#39; library(dplyr); library(readr); library(BiocParallel)
#&#39; txs &amp;lt;- transcripts(TxDb.Hsapiens.UCSC.hg19.knownGene)
#&#39; scores&amp;lt;- TssEnrichmentFromFrags(&amp;quot;fragment.tsv.gz&amp;quot;, txs = txs)

TssEnrichmentFromFrags &amp;lt;- function(frag_gz_file,
                               txs,
                               flank = 1000,
                               endFlank = 100,
                               highest_tss_flank= 50,
                               smooth = 50,
                               strand.aware = TRUE,
                               workers = 1,
                               barcodeList = NULL){
        
        # Make GRanges of fragments that are solid for the cells that we care about
        frags_valid &amp;lt;- data.table::fread(paste0(&amp;quot;zcat &amp;lt; &amp;quot;, frag_gz_file)) %&amp;gt;% 
                data.frame() %&amp;gt;% 
                mutate(V2 = V2 + 1) %&amp;gt;% # make it 1 based for R
                GenomicRanges::makeGRangesFromDataFrame(seqnames.field = &amp;quot;V1&amp;quot;, start.field = &amp;quot;V2&amp;quot;, end.field = &amp;quot;V3&amp;quot;, keep.extra.columns = TRUE)
        if (!is.null(barcodeList)){
                validBarcodes&amp;lt;- read_tsv(barcodeList, col_names = F)
                frags_valid&amp;lt;- frags_valid[frags_valid$V4 %in% validBarcodes$X1]
        }
        
        # common chromosome names, do it per cell instead, see TssEnrichmentSingleCell
        seqlev&amp;lt;- intersect(seqlevels(frags_valid), seqlevels(txs))
        frags_valid&amp;lt;- keepSeqlevels(frags_valid, seqlev, pruning.mode=&amp;quot;coarse&amp;quot;)
        
        # calculate coverage per cell
        frags_valid_per_cell&amp;lt;- split(frags_valid, frags_valid$V4)
        
       
        # this step can take minutes 
        multicoreParam &amp;lt;- BiocParallel::MulticoreParam(workers = workers)
        # can add the chromosome length as additional argument for `coverage`
        # to get 0 coverages if there are no reads there. 
        cvgs&amp;lt;- bplapply(frags_valid_per_cell, function(x) coverage(x), BPPARAM = multicoreParam)
        
        txs &amp;lt;- unique(txs)
        
        txs.flanks&amp;lt;- promoters(txs, upstream = flank, 
                            downstream = flank)
        txs.length&amp;lt;- length(txs.flanks)
        
        TssEnrichmentScores&amp;lt;- BiocParallel::bplapply(cvgs, TssEnrichmentSingleCell, txs.flanks, strand.aware = strand.aware, endFlank = endFlank, flank = flank, highest_tss_flank, smooth = smooth, BPPARAM = multicoreParam)

        enrichment&amp;lt;- do.call(&amp;quot;rbind&amp;quot;, TssEnrichmentScores)
        return(enrichment)
}    

TssEnrichmentSingleCell&amp;lt;- function(cvg, txs.flanks, strand.aware = TRUE, flank = 1000,
                               endFlank = 100,
                               highest_tss_flank= 50,
                               smooth = 50 ){
        ## remove tss not in the coverage and assign a unique id for each tss: X_rank
        txs.flanks&amp;lt;- constrainRanges(cvg, txs.flanks)
        txs.length&amp;lt;- length(txs.flanks)
        if(length(txs.flanks)!=txs.length){
              warning(paste0(txs.length-length(txs.flanks),
                             &amp;quot; Tss removed because they fall out of the coverage&amp;quot;))
            }
        # common chromosomes
        chrs&amp;lt;- sort(intersect(names(cvg), as.character(unique(seqnames(txs.flanks)))))
        
        # convert GRanges to IntergerRangesList does not maintain the order
        # a unique id was given for each Ranges
        myViews&amp;lt;- Views(cvg[chrs],as(txs.flanks,&amp;quot;IntegerRangesList&amp;quot;)[chrs]) # get subsets of RleList
        mat = lapply(myViews,function(x) t(viewApply(x,as.vector)) )
        mat = do.call(&amp;quot;rbind&amp;quot;,mat)
        
        r.list=split(mcols(txs.flanks)[,&amp;quot;X_rank&amp;quot;], as.vector(seqnames(txs.flanks))  )
        r.list=r.list[order(names(r.list))]
        ranks=do.call(&amp;quot;c&amp;quot;,r.list)
        rownames(mat) = ranks
        
        if(strand.aware == TRUE){
              orig.rows=txs.flanks[strand(txs.flanks) == &#39;-&#39;,]$X_rank
              mat[rownames(mat) %in% orig.rows,] = mat[rownames(mat) %in% 
                                                         orig.rows, ncol(mat):1]
        }
        
        # reorder according to the original Granges (txs)
        mat = mat[order(ranks),]
        
  
        ### normlization by the endFlank local noise
        profile &amp;lt;- colSums(mat)
        profile_norm &amp;lt;- profile/mean(profile[c(1:endFlank,(flank*2-endFlank+1):(flank*2))])

        #smooth
        profile_norm_smooth &amp;lt;- zoo::rollmean(profile_norm, smooth, fill = 1)
        

        #enrichment
        max_finite &amp;lt;- function(x){
        suppressWarnings(max(x[is.finite(x)], na.rm=TRUE))
        }
        
        e &amp;lt;- max_finite(profile_norm_smooth[(flank-highest_tss_flank):(flank+highest_tss_flank)])
        return(e)
}


&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>clustering scATACseq data: the TF-IDF way</title>
      <link>/post/clustering-scatacseq-data-the-tf-idf-way/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/clustering-scatacseq-data-the-tf-idf-way/</guid>
      <description>&lt;p&gt;scATACseq data are very sparse. It is sparser than scRNAseq. To do clustering of
scATACseq data, there are some preprocessing steps need to be done.&lt;/p&gt;
&lt;p&gt;I want to reproduce what has been done after reading the method section of these two recent scATACseq paper:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/30078704&#34;&gt;A Single-Cell Atlas of In Vivo Mammalian Chromatin Accessibility&lt;/a&gt;
Darren et.al Cell 2018&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Latent Semantic Indexing Cluster Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to get an initial sense of the relationship between individual cells, &lt;strong&gt;we first broke the genome into 5kb windows and then scored each cell for any insertions in these windows, generating a large, sparse, binary matrix of 5kb windows by cells for each tissue.&lt;/strong&gt; Based on this matrix, we retained the top 20,000 most commonly used sites in each tissue (this number could extend a little above 20,000 because we included tied sites at the threshold) and then filtered out the bottom 5% of cells in terms of the number of 5kb windows with any insertions. We then reduced the dimensionality of these large binary matrices using a term &lt;strong&gt;frequency-inverse document frequency (‘‘TF-IDF’’) transformation.&lt;/strong&gt; To do this, we first weighted all the sites for individual cells by the total number of sites accessible in that cell (‘‘term frequency’’). We then multiplied these weighted values by log(1 + the inverse frequency of each site across all cells), the ‘‘inverse document frequency.’’ We then used singular value decomposition on the TF-IDF matrix to generate a lower dimensional representation of the data by only retaining the 2nd through 10th dimensions (because the first dimension tends to be highly correlated with read depth). These LSI-transformed scores of accessibility were then standardized by row (i.e., mean subtracted and divided by standard deviation), capped at ± 1.5, and used to bi-cluster cells and windows based on cosine distances using the ward algorithm in R. Visual examination of the resulting heatmaps identified between 2 and 7 distinct clusters of cells, de- pending on the tissue. These relatively crude groups of cells were used for peak calling (described below) to maintain enough cells in each group for identifying peaks while also retaining sufficient sensitivity to identify peaks that were restricted to subset of cells.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t-distributed Stochastic Neighbor Embedding and Iterative Cluster Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To take a more holistic approach to understanding the relationships of different cell types across the entire dataset, we combined all cells from all tissues and used the t-distributed stochastic neighbor embedding dimensionality reduction technique to visualize the full dataset and identify clusters of cells representing individual cell types. &lt;strong&gt;As with the LSI analysis above, we started by generating a large binary matrix of sites by cells, but instead of scoring cells for reads overlapping 5kb windows in the genome we scored cells for reads overlapping the master list of potential regulatory elements we had previously identified based on LSI clusters.&lt;/strong&gt; Starting with all cells that passed our nucleosome signal and read depth thresholds, we again wanted to remove the most sparsely sampled sites and cells to more clearly define differences between cell types. To do so, we first filtered out any sites that were not observed as accessible in at least 5% of cells in at least one LSI cluster and then filtered out cells that were more than 1 standard deviation below the mean number of sites observed. We then transformed this matrix with the TF-IDF algorithm described above. Finally, we generated a lower dimen- sional representation of the data by including the first 50 dimensions of the singular value decomposition of this TF-IDF-transformed matrix. This representation was then used as input for the Rtsne package in R (Krijthe, 2015). To identify clusters of cells in this two dimensional representation of the data, we used the Louvain clustering algorithm implemented in Seurat (Satija et al., 2015). Resolu- tion and K parameters for Louvain clustering were chosen for each major cluster to produce reasonable groupings of cells that are well- separated in each t-SNE embedding. This analysis identified 30 distinct clusters of cells, but to get at even finer structure, we subset TF-IDF normalized data on each of these 30 clusters of cells and repeated SVD and t-SNE to identify subclusters, again using Louvain clustering. Through this round of ‘‘iterative’’ t-SNE, we identified a total of 85 distinct clusters. Note that for one major cluster, major cluster 12, we found that Monocle 20s implementation of density peak clustering (Qiu et al., 2017; Trapnell et al., 2014) seemed to produce more reasonable clusters. Rho and delta parameters were set in the same manner as for Louvain clustering.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/610550v1&#34;&gt;Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion&lt;/a&gt;
Ansuman et.al 2019 biorxiv&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;ATAC-seq-centric Latent Semantic Indexing clustering and visualization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We clustered scATAC-seq data using an approach that does not require bulk data or prior
knowledge. To achieve this, we adopted the strategy by Cusanovich et. al9, to compute
the term frequency-inverse document frequency (“TF-IDF”) transformation. Briefly we
divided each index by the colSums of the matrix to compute the cell “term frequency.”
Next, we multiplied these values by log(1 + ncol(matrix) / rowSums(matrix)), which
represents the “inverse document frequency.” This resulted in a TF-IDF matrix that was
used as input to irlba’s singular value decomposition (SVD) implementation in R. We then
used the first 50 reduced dimensions as input into a Seurat object and then crude clusters
were identified by using Seurat’s (v2.3) SNN graph clustering “FindClusters” with a default
resolution of 0.8. We found that there was detectable batch effect that confounded further
analyses. To attenuate this batch effect, we calculated the cluster sums from the binarized
accessibility matrix and then log-normalized by using edgeR’s “cpm(matrix , log = TRUE,
prior.count = 3)” in R. Next, we identified the top 25,000 varying peaks across all clusters
using “rowVars” in R. This was done on the cluster log-normalized matrix vs the sparse
binary matrix because: (1) it reduced biases due to cluster cell sizes, and (2) it attenuated
the mean-variability relationship by converting to log space with a scaled prior count.
These 25,000 variable peaks were then used to subset the sparse binarized accessibility
matrix and recomputed the “TF-IDF” transform. We used singular value decomposition
on the TF-IDF matrix to generate a lower dimensional representation of the data by
retaining the first 50 dimensions. We then used these reduced dimensions as input into
a Seurat object and then crude clusters were identified by using Seurat’s (v2.3) SNN
graph clustering “FindClusters” with a default resolution of 0.8. These same reduced
dimensions were used as input to Seurat’s “RunUMAP” with default parameters and
plotted in ggplot2 using R&lt;/p&gt;
&lt;p&gt;Both papers used the so called &lt;code&gt;Latent Semantic Indexing&lt;/code&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Latent_semantic_analysis&#34;&gt;LSI method&lt;/a&gt; and used a transformation of the
binarized scATAC count matrix called ’TF-IDF` (term frequency–inverse document frequency) which is
used in text mining. TF-IDF can be used for scRNAseq data as well. see &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6101073/&#34;&gt;Single cell RNA-seq data clustering using TF-IDF based methods&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The transformation is not complicated as described above:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Briefly we divided each index by the colSums of the matrix to compute the cell “term frequency.”
Next, we multiplied these values by log(1 + ncol(matrix) / rowSums(matrix)), which
represents the “inverse document frequency.” This resulted in a TF-IDF matrix&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Seurat&lt;/code&gt; version 3 has a function called &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/preprocessing.R#L1253&#34;&gt;&lt;code&gt;TF.IDF&lt;/code&gt;&lt;/a&gt; for that purpose.&lt;/p&gt;
&lt;p&gt;But note that, it does not do the log transformation in this function, but do it at &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&#34; class=&#34;uri&#34;&gt;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I will first show you the long way to do the clustering through which I want to gain some more
deep understanding of the whole process and I will show you how to use &lt;code&gt;Seurat&lt;/code&gt; V3 for that.&lt;/p&gt;
&lt;p&gt;I am going to use the 10k pbmc scATAC data from 10x for demonstration. You can download the data from
&lt;a href=&#34;https://support.10xgenomics.com/single-cell-atac/datasets/1.1.0/atac_v1_pbmc_10k&#34; class=&#34;uri&#34;&gt;https://support.10xgenomics.com/single-cell-atac/datasets/1.1.0/atac_v1_pbmc_10k&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;the-long-way&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The long way&lt;/h3&gt;
&lt;p&gt;read in the sparse matrix&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
library(readr)
library(dplyr)
mat&amp;lt;- readMM(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/matrix.mtx&amp;quot;)
peaks&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/peaks.bed&amp;quot;, col_names = F)
peaks&amp;lt;- peaks %&amp;gt;%
        mutate(id1 = paste(X2, X3, sep = &amp;quot;-&amp;quot;)) %&amp;gt;%
        mutate(id = paste(X1, id1, sep = &amp;quot;:&amp;quot;))
        
barcodes&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/barcodes.tsv&amp;quot;, col_names =F)

rownames(mat)&amp;lt;- peaks$id1
colnames(mat)&amp;lt;- barcodes$X1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;binarize the data and do TF-IDF transformation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# binarize the matrix 
mat@x[mat@x &amp;gt;0]&amp;lt;- 1 

TF.IDF.custom &amp;lt;- function(data, verbose = TRUE) {
  if (class(x = data) == &amp;quot;data.frame&amp;quot;) {
    data &amp;lt;- as.matrix(x = data)
  }
  if (class(x = data) != &amp;quot;dgCMatrix&amp;quot;) {
    data &amp;lt;- as(object = data, Class = &amp;quot;dgCMatrix&amp;quot;)
  }
  if (verbose) {
    message(&amp;quot;Performing TF-IDF normalization&amp;quot;)
  }
  npeaks &amp;lt;- Matrix::colSums(x = data)
  tf &amp;lt;- t(x = t(x = data) / npeaks)
  # log transformation
  idf &amp;lt;- log(1+ ncol(x = data) / Matrix::rowSums(x = data))
  norm.data &amp;lt;- Diagonal(n = length(x = idf), x = idf) %*% tf
  norm.data[which(x = is.na(x = norm.data))] &amp;lt;- 0
  return(norm.data)
}


mat&amp;lt;- TF.IDF.custom(mat)

# what&amp;#39;s the range after transformation?
range(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00000000 0.01111942&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 89796  8728&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dimension reduction with SVD, use &lt;code&gt;irlba::irlba&lt;/code&gt; for approximated calculation.&lt;/p&gt;
&lt;p&gt;Note: &lt;code&gt;svd&lt;/code&gt; singular value decomposition gives the same results as &lt;code&gt;prcomp&lt;/code&gt;for exact PC calculation.
see my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/pca-in-action/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(irlba)
set.seed(123)
mat.lsi&amp;lt;- irlba(mat, 50)

d_diagtsne &amp;lt;- matrix(0, 50, 50)
diag(d_diagtsne) &amp;lt;- mat.lsi$d
mat_pcs &amp;lt;- t(d_diagtsne %*% t(mat.lsi$v))
dim(mat_pcs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8728   50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PCA plot PC1 vs PC2
plot(mat_pcs[,1], mat_pcs[,2])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(mat_pcs)&amp;lt;- colnames(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;clustering in the PCA space using KNN.&lt;/p&gt;
&lt;p&gt;I took some code from &lt;a href=&#34;https://jef.works/blog/2017/09/13/graph-based-community-detection-for-clustering-analysis/&#34;&gt;Jean Fan’s blog post&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RANN)
knn.info&amp;lt;- RANN::nn2(mat_pcs, k = 30)

## convert to adjacancy matrix
knn &amp;lt;- knn.info$nn.idx

adj &amp;lt;- matrix(0, nrow(mat_pcs), nrow(mat_pcs))
rownames(adj) &amp;lt;- colnames(adj) &amp;lt;- rownames(mat_pcs)

for(i in seq_len(nrow(mat_pcs))) {
    adj[i,rownames(mat_pcs)[knn[i,]]] &amp;lt;- 1
}

## convert to graph
library(igraph)
g &amp;lt;- igraph::graph.adjacency(adj, mode=&amp;quot;undirected&amp;quot;)
g &amp;lt;- simplify(g) ## remove self loops

## identify communities, many algorithums. Use the Louvain clustering

km &amp;lt;- igraph::cluster_louvain(g)

com &amp;lt;- km$membership
names(com) &amp;lt;- km$names

# cluster id for each barcode
head(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## AAACGAAAGAGCGAAA-1 AAACGAAAGAGTTTGA-1 AAACGAAAGCGAGCTA-1 
##                  7                 14                  2 
## AAACGAAAGGCTTCGC-1 AAACGAAAGTGCTGAG-1 AAACGAACAAGGGTAC-1 
##                 11                  1                 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total 13 clusters
table(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## com
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 
## 1776  389  482   34 1100  520  491  640  781  487  204  888  173  763&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;t-SNE for visualization&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rtsne)
library(ggplot2)
library(tibble)
set.seed(345)

mat_tsne&amp;lt;- Rtsne(mat_pcs,  dims = 2, perplexity = 30, verbose = TRUE, 
               max_iter = 1000, check_duplicates = FALSE, is_distance = FALSE, 
               theta = 0.5, pca = FALSE, exaggeration_factor = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Read the 8728 x 50 data matrix successfully!
## OpenMP is working. 1 threads.
## Using no_dims = 2, perplexity = 30.000000, and theta = 0.500000
## Computing input similarities...
## Building tree...
## Done in 1.81 seconds (sparsity = 0.015574)!
## Learning embedding...
## Iteration 50: error is 94.027001 (50 iterations in 1.63 seconds)
## Iteration 100: error is 80.430931 (50 iterations in 1.34 seconds)
## Iteration 150: error is 77.384844 (50 iterations in 1.10 seconds)
## Iteration 200: error is 76.435871 (50 iterations in 1.12 seconds)
## Iteration 250: error is 75.985857 (50 iterations in 1.16 seconds)
## Iteration 300: error is 2.655848 (50 iterations in 1.02 seconds)
## Iteration 350: error is 2.321504 (50 iterations in 1.02 seconds)
## Iteration 400: error is 2.140627 (50 iterations in 1.05 seconds)
## Iteration 450: error is 2.024543 (50 iterations in 1.06 seconds)
## Iteration 500: error is 1.944114 (50 iterations in 1.06 seconds)
## Iteration 550: error is 1.884803 (50 iterations in 1.10 seconds)
## Iteration 600: error is 1.840703 (50 iterations in 1.14 seconds)
## Iteration 650: error is 1.806387 (50 iterations in 1.06 seconds)
## Iteration 700: error is 1.780991 (50 iterations in 1.07 seconds)
## Iteration 750: error is 1.761708 (50 iterations in 1.07 seconds)
## Iteration 800: error is 1.747014 (50 iterations in 1.10 seconds)
## Iteration 850: error is 1.735953 (50 iterations in 1.07 seconds)
## Iteration 900: error is 1.728716 (50 iterations in 1.11 seconds)
## Iteration 950: error is 1.725798 (50 iterations in 1.13 seconds)
## Iteration 1000: error is 1.724810 (50 iterations in 1.21 seconds)
## Fitting performed in 22.62 seconds.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_tsne&amp;lt;- as.data.frame(mat_tsne$Y)
colnames(df_tsne)&amp;lt;- c(&amp;quot;tSNE1&amp;quot;, &amp;quot;tSNE2&amp;quot;)
df_tsne$barcode&amp;lt;- rownames(mat_pcs)

df_tsne&amp;lt;- left_join(df_tsne, enframe(com), by = c(&amp;quot;barcode&amp;quot; = &amp;quot;name&amp;quot;)) %&amp;gt;%
        dplyr::rename(cluster = value) %&amp;gt;%
        mutate(cluster = as.factor(cluster))


ggplot(df_tsne, aes(x = tSNE1, y = tSNE2)) + 
        geom_point(aes(col = cluster), size = 0.5) +
        theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks pretty good :)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-easier-way-use-seurat&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The easier way: use Seurat&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
peaks &amp;lt;- Read10X_h5(filename = &amp;quot;/Users/mingtang/github_repos/blogdown_data/atac_v1_pbmc_10k_filtered_peak_bc_matrix.h5&amp;quot;)

# binarize the matrix
peaks@x[peaks@x &amp;gt;0]&amp;lt;- 1 

## create a seurat object
atac.lsi &amp;lt;- CreateSeuratObject(counts = peaks, assay = &amp;#39;ATAC&amp;#39;, project = &amp;#39;10k_pbmc&amp;#39;)

atac.lsi &amp;lt;- RunLSI(object = atac.lsi, n = 50, scale.max = NULL)

# atac.lsi@reductions

atac.lsi&amp;lt;- FindNeighbors(atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 1:50)
atac.lsi&amp;lt;- FindClusters(atac.lsi, resolution = 0.8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
## 
## Number of nodes: 8728
## Number of edges: 246454
## 
## Running Louvain algorithm...
## Maximum modularity in 10 random starts: 0.9129
## Number of communities: 20
## Elapsed time: 0 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;atac.lsi &amp;lt;- RunTSNE(object = atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 1:50)
DimPlot(object = atac.lsi, reduction = &amp;#39;tsne&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You may argue those two t-SNE graphs look very different in terms of number of clusters
and the shape of the clusters. And I agree. There are many reasons for that.
I hope &lt;code&gt;Seurat&lt;/code&gt; team can give some insights.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;code&gt;TF-IDF&lt;/code&gt; function in &lt;code&gt;Seurat&lt;/code&gt; does not do log transformation
as in the papers: &lt;code&gt;idf &amp;lt;- log(1+ ncol(x = data) / Matrix::rowSums(x = data))&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;but rather do a log transformation &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&#34;&gt;later&lt;/a&gt;: &lt;code&gt;tf.idf &amp;lt;- LogNorm(data = tf.idf, display_progress = verbose, scale_factor = 1e4)&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I am not an expert in the graph clustering, but the clustering algorithm in
&lt;code&gt;Seurat&lt;/code&gt; is probably not exactly the same with &lt;code&gt;igraph::cluster_louvain&lt;/code&gt;.
Moreover, one can always tweak the k.param and resolution parameters, and the cluster number changes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can compare the cell identities for each cluster&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/crazyhottommy/scclusteval
library(scclusteval)

# takes two named vector, and calculate the pairwise Jaccard similarity score
# for all clusters
PairWiseJaccardSetsHeatmap(com, Idents(atac.lsi))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-other-notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Some other notes&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It is known that first dimension is correlated with sequencing depth (although Ansuman et.al did not find such). Nevertheless, if you see such correlation, when cluster
cells in the PC space, you can exclude the first PC. e.g. &lt;code&gt;atac.lsi&amp;lt;- FindNeighbors(atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 2:50)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I did not do &lt;code&gt;LSI&lt;/code&gt; first for crude clustering using the titled 5kb genome bin matrix and call peaks for each crude cluster and then get the count matrix per peak per cell. I am not sure how much this extra work can benefit the clustering.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It turns out the &lt;code&gt;TF-IDF&lt;/code&gt; transformation is critical for this sparse matrix. If you do not do it, you will find your t-SNE plot looks really funky! do not trust me, try it yourself:)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for clustering scATAC data, one can use the peak x cell matrix or derive a gene activity score by tools such as &lt;a href=&#34;https://cole-trapnell-lab.github.io/cicero-release/&#34;&gt;&lt;code&gt;Cicero&lt;/code&gt;&lt;/a&gt; to generate a gene x cell matrix. This is useful when you want to transfer the RNAseq cell type labels to the scATACseq data. see more details in the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/460147v1&#34;&gt;Seurat V3 paper&lt;/a&gt;. The question is then, which matrix should we use for clustering? The clustering of these two different matrix can be different but there should be no surprise. We can use the gene activity score matrix as a label transferring mediator and get the cell labels and then super-impose the cluster id to the t-SNE plot clustered by the peak x cell matrix.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgements&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acknowledgements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I want to thank 10x genomics for making the data publicly available.&lt;/li&gt;
&lt;li&gt;I want to thank &lt;a href=&#34;https://jef.works/blog/2017/09/13/graph-based-community-detection-for-clustering-analysis/&#34;&gt;Jean Fan&lt;/a&gt; for putting up some nice posts.&lt;/li&gt;
&lt;li&gt;I want to thank Tim Stuart for answering questions with &lt;code&gt;Seurat&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I got some ideas from &lt;a href=&#34;https://github.com/jaychung10010/Mammary_snATAC-seq&#34; class=&#34;uri&#34;&gt;https://github.com/jaychung10010/Mammary_snATAC-seq&lt;/a&gt; as well. Thanks for posting the codes.&lt;/li&gt;
&lt;li&gt;I want to thank everyone else who give help and suggestions along my adventure of analyzing scATACseq data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;update&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UPDATE&lt;/h3&gt;
&lt;p&gt;Do the IF-IDF Seurat way&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
library(readr)
library(dplyr)
mat&amp;lt;- readMM(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/matrix.mtx&amp;quot;)
peaks&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/peaks.bed&amp;quot;, col_names = F)
peaks&amp;lt;- peaks %&amp;gt;%
        mutate(id1 = paste(X2, X3, sep = &amp;quot;-&amp;quot;)) %&amp;gt;%
        mutate(id = paste(X1, id1, sep = &amp;quot;:&amp;quot;))
        
barcodes&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/barcodes.tsv&amp;quot;, col_names =F)

rownames(mat)&amp;lt;- peaks$id1
colnames(mat)&amp;lt;- barcodes$X1
# binarize the matrix 
mat@x[mat@x &amp;gt;0]&amp;lt;- 1 
# Seurat version TF-IDF
mat&amp;lt;- TF.IDF(mat)
mat&amp;lt;- LogNormalize(mat,scale_factor = 1e4)

### SVD
library(irlba)
set.seed(123)
mat.lsi&amp;lt;- irlba(mat, 50)

d_diagtsne &amp;lt;- matrix(0, 50, 50)
diag(d_diagtsne) &amp;lt;- mat.lsi$d
mat_pcs &amp;lt;- t(d_diagtsne %*% t(mat.lsi$v))
dim(mat_pcs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8728   50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PCA plot PC1 vs PC2
plot(mat_pcs[,1], mat_pcs[,2])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(mat_pcs)&amp;lt;- colnames(mat)

library(RANN)
knn.info&amp;lt;- RANN::nn2(mat_pcs, k = 30)

## convert to adjacancy matrix
knn &amp;lt;- knn.info$nn.idx

adj &amp;lt;- matrix(0, nrow(mat_pcs), nrow(mat_pcs))
rownames(adj) &amp;lt;- colnames(adj) &amp;lt;- rownames(mat_pcs)

for(i in seq_len(nrow(mat_pcs))) {
    adj[i,rownames(mat_pcs)[knn[i,]]] &amp;lt;- 1
}

## convert to graph
library(igraph)
g &amp;lt;- igraph::graph.adjacency(adj, mode=&amp;quot;undirected&amp;quot;)
g &amp;lt;- simplify(g) ## remove self loops

## identify communities, many algorithums. Use the Louvain clustering

km &amp;lt;- igraph::cluster_louvain(g)

com &amp;lt;- km$membership
names(com) &amp;lt;- km$names

# cluster id for each barcode
head(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## AAACGAAAGAGCGAAA-1 AAACGAAAGAGTTTGA-1 AAACGAAAGCGAGCTA-1 
##                 13                  7                 12 
## AAACGAAAGGCTTCGC-1 AAACGAAAGTGCTGAG-1 AAACGAACAAGGGTAC-1 
##                 14                 13                 16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total 13 clusters
table(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## com
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 
##  801  376  617  629  572   56  607  435  280  390  131  417 2554  490  241 
##   16 
##  132&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### T-sne visualization
library(Rtsne)
library(ggplot2)
library(tibble)
set.seed(345)

mat_tsne&amp;lt;- Rtsne(mat_pcs,  dims = 2, perplexity = 30, verbose = TRUE, 
               max_iter = 1000, check_duplicates = FALSE, is_distance = FALSE, 
               theta = 0.5, pca = FALSE, exaggeration_factor = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Read the 8728 x 50 data matrix successfully!
## OpenMP is working. 1 threads.
## Using no_dims = 2, perplexity = 30.000000, and theta = 0.500000
## Computing input similarities...
## Building tree...
## Done in 2.57 seconds (sparsity = 0.014984)!
## Learning embedding...
## Iteration 50: error is 94.871477 (50 iterations in 1.48 seconds)
## Iteration 100: error is 84.409610 (50 iterations in 1.50 seconds)
## Iteration 150: error is 82.319098 (50 iterations in 1.18 seconds)
## Iteration 200: error is 81.831573 (50 iterations in 1.35 seconds)
## Iteration 250: error is 81.608255 (50 iterations in 1.40 seconds)
## Iteration 300: error is 3.039995 (50 iterations in 1.20 seconds)
## Iteration 350: error is 2.691975 (50 iterations in 1.14 seconds)
## Iteration 400: error is 2.508723 (50 iterations in 1.24 seconds)
## Iteration 450: error is 2.390684 (50 iterations in 1.14 seconds)
## Iteration 500: error is 2.308249 (50 iterations in 1.16 seconds)
## Iteration 550: error is 2.248218 (50 iterations in 1.12 seconds)
## Iteration 600: error is 2.201765 (50 iterations in 1.27 seconds)
## Iteration 650: error is 2.166028 (50 iterations in 1.21 seconds)
## Iteration 700: error is 2.137659 (50 iterations in 1.13 seconds)
## Iteration 750: error is 2.115987 (50 iterations in 1.11 seconds)
## Iteration 800: error is 2.098913 (50 iterations in 1.16 seconds)
## Iteration 850: error is 2.086752 (50 iterations in 1.08 seconds)
## Iteration 900: error is 2.079435 (50 iterations in 1.07 seconds)
## Iteration 950: error is 2.078012 (50 iterations in 1.14 seconds)
## Iteration 1000: error is 2.076638 (50 iterations in 1.12 seconds)
## Fitting performed in 24.21 seconds.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_tsne&amp;lt;- as.data.frame(mat_tsne$Y)
colnames(df_tsne)&amp;lt;- c(&amp;quot;tSNE1&amp;quot;, &amp;quot;tSNE2&amp;quot;)
df_tsne$barcode&amp;lt;- rownames(mat_pcs)

df_tsne&amp;lt;- left_join(df_tsne, enframe(com), by = c(&amp;quot;barcode&amp;quot; = &amp;quot;name&amp;quot;)) %&amp;gt;%
        dplyr::rename(cluster = value) %&amp;gt;%
        mutate(cluster = as.factor(cluster))

ggplot(df_tsne, aes(x = tSNE1, y = tSNE2)) + 
        geom_point(aes(col = cluster), size = 0.5) +
        theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, it still looks different from the &lt;code&gt;Seurat&lt;/code&gt; output. Any comments?&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
